// Generated by ScalaBuff, the Scala Protocol Buffers compiler. DO NOT EDIT!
// source: riak_kv.proto

package com.basho.riak.protobuf

//import "riak.proto"

final case class RpbGetClientIdResp(
  `clientId`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbGetClientIdResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbGetClientIdResp] {

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `clientId`)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `clientId`)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbGetClientIdResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __clientId: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY

      def __newMerged = RpbGetClientIdResp(
        __clientId)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __clientId = in.readBytes()
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbGetClientIdResp) = {
    RpbGetClientIdResp(
      m.`clientId`)
  }

  def getDefaultInstanceForType = RpbGetClientIdResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbGetClientIdResp {
  @beans.BeanProperty val defaultInstance = new RpbGetClientIdResp()

  def parseFrom(data: Array[Byte]): RpbGetClientIdResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbGetClientIdResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbGetClientIdResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbGetClientIdResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbGetClientIdResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val CLIENT_ID_FIELD_NUMBER = 1

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbGetClientIdResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbSetClientIdReq(
  `clientId`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbSetClientIdReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbSetClientIdReq] {

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `clientId`)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `clientId`)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbSetClientIdReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __clientId: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY

      def __newMerged = RpbSetClientIdReq(
        __clientId)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __clientId = in.readBytes()
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbSetClientIdReq) = {
    RpbSetClientIdReq(
      m.`clientId`)
  }

  def getDefaultInstanceForType = RpbSetClientIdReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbSetClientIdReq {
  @beans.BeanProperty val defaultInstance = new RpbSetClientIdReq()

  def parseFrom(data: Array[Byte]): RpbSetClientIdReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbSetClientIdReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbSetClientIdReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbSetClientIdReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbSetClientIdReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val CLIENT_ID_FIELD_NUMBER = 1

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbSetClientIdReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbGetReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `r`: Option[Int] = None,
  `pr`: Option[Int] = None,
  `basicQuorum`: Option[Boolean] = None,
  `notfoundOk`: Option[Boolean] = None,
  `ifModified`: Option[com.google.protobuf.ByteString] = None,
  `head`: Option[Boolean] = None,
  `deletedvclock`: Option[Boolean] = None,
  `timeout`: Option[Int] = None,
  `sloppyQuorum`: Option[Boolean] = None,
  `nVal`: Option[Int] = None,
  `type`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbGetReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbGetReq] {

  def setR(_f: Int) = copy(`r` = Some(_f))
  def setPr(_f: Int) = copy(`pr` = Some(_f))
  def setBasicQuorum(_f: Boolean) = copy(`basicQuorum` = Some(_f))
  def setNotfoundOk(_f: Boolean) = copy(`notfoundOk` = Some(_f))
  def setIfModified(_f: com.google.protobuf.ByteString) = copy(`ifModified` = Some(_f))
  def setHead(_f: Boolean) = copy(`head` = Some(_f))
  def setDeletedvclock(_f: Boolean) = copy(`deletedvclock` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setSloppyQuorum(_f: Boolean) = copy(`sloppyQuorum` = Some(_f))
  def setNVal(_f: Int) = copy(`nVal` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))

  def clearR = copy(`r` = None)
  def clearPr = copy(`pr` = None)
  def clearBasicQuorum = copy(`basicQuorum` = None)
  def clearNotfoundOk = copy(`notfoundOk` = None)
  def clearIfModified = copy(`ifModified` = None)
  def clearHead = copy(`head` = None)
  def clearDeletedvclock = copy(`deletedvclock` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearSloppyQuorum = copy(`sloppyQuorum` = None)
  def clearNVal = copy(`nVal` = None)
  def clearType = copy(`type` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `key`)
    if (`r`.isDefined) output.writeUInt32(3, `r`.get)
    if (`pr`.isDefined) output.writeUInt32(4, `pr`.get)
    if (`basicQuorum`.isDefined) output.writeBool(5, `basicQuorum`.get)
    if (`notfoundOk`.isDefined) output.writeBool(6, `notfoundOk`.get)
    if (`ifModified`.isDefined) output.writeBytes(7, `ifModified`.get)
    if (`head`.isDefined) output.writeBool(8, `head`.get)
    if (`deletedvclock`.isDefined) output.writeBool(9, `deletedvclock`.get)
    if (`timeout`.isDefined) output.writeUInt32(10, `timeout`.get)
    if (`sloppyQuorum`.isDefined) output.writeBool(11, `sloppyQuorum`.get)
    if (`nVal`.isDefined) output.writeUInt32(12, `nVal`.get)
    if (`type`.isDefined) output.writeBytes(13, `type`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `key`)
    if (`r`.isDefined) __size += computeUInt32Size(3, `r`.get)
    if (`pr`.isDefined) __size += computeUInt32Size(4, `pr`.get)
    if (`basicQuorum`.isDefined) __size += computeBoolSize(5, `basicQuorum`.get)
    if (`notfoundOk`.isDefined) __size += computeBoolSize(6, `notfoundOk`.get)
    if (`ifModified`.isDefined) __size += computeBytesSize(7, `ifModified`.get)
    if (`head`.isDefined) __size += computeBoolSize(8, `head`.get)
    if (`deletedvclock`.isDefined) __size += computeBoolSize(9, `deletedvclock`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(10, `timeout`.get)
    if (`sloppyQuorum`.isDefined) __size += computeBoolSize(11, `sloppyQuorum`.get)
    if (`nVal`.isDefined) __size += computeUInt32Size(12, `nVal`.get)
    if (`type`.isDefined) __size += computeBytesSize(13, `type`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbGetReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __r: Option[Int] = `r`
    var __pr: Option[Int] = `pr`
    var __basicQuorum: Option[Boolean] = `basicQuorum`
    var __notfoundOk: Option[Boolean] = `notfoundOk`
    var __ifModified: Option[com.google.protobuf.ByteString] = `ifModified`
    var __head: Option[Boolean] = `head`
    var __deletedvclock: Option[Boolean] = `deletedvclock`
    var __timeout: Option[Int] = `timeout`
    var __sloppyQuorum: Option[Boolean] = `sloppyQuorum`
    var __nVal: Option[Int] = `nVal`
    var __type: Option[com.google.protobuf.ByteString] = `type`

      def __newMerged = RpbGetReq(
        __bucket,
        __key,
        __r,
        __pr,
        __basicQuorum,
        __notfoundOk,
        __ifModified,
        __head,
        __deletedvclock,
        __timeout,
        __sloppyQuorum,
        __nVal,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = in.readBytes()
      case 24      ⇒ __r = Some(in.readUInt32())
      case 32      ⇒ __pr = Some(in.readUInt32())
      case 40      ⇒ __basicQuorum = Some(in.readBool())
      case 48      ⇒ __notfoundOk = Some(in.readBool())
      case 58      ⇒ __ifModified = Some(in.readBytes())
      case 64      ⇒ __head = Some(in.readBool())
      case 72      ⇒ __deletedvclock = Some(in.readBool())
      case 80      ⇒ __timeout = Some(in.readUInt32())
      case 88      ⇒ __sloppyQuorum = Some(in.readBool())
      case 96      ⇒ __nVal = Some(in.readUInt32())
      case 106     ⇒ __type = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbGetReq) = {
    RpbGetReq(
      m.`bucket`,
      m.`key`,
      m.`r`.orElse(`r`),
      m.`pr`.orElse(`pr`),
      m.`basicQuorum`.orElse(`basicQuorum`),
      m.`notfoundOk`.orElse(`notfoundOk`),
      m.`ifModified`.orElse(`ifModified`),
      m.`head`.orElse(`head`),
      m.`deletedvclock`.orElse(`deletedvclock`),
      m.`timeout`.orElse(`timeout`),
      m.`sloppyQuorum`.orElse(`sloppyQuorum`),
      m.`nVal`.orElse(`nVal`),
      m.`type`.orElse(`type`))
  }

  def getDefaultInstanceForType = RpbGetReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbGetReq {
  @beans.BeanProperty val defaultInstance = new RpbGetReq()

  def parseFrom(data: Array[Byte]): RpbGetReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbGetReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbGetReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbGetReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbGetReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val R_FIELD_NUMBER = 3
  val PR_FIELD_NUMBER = 4
  val BASIC_QUORUM_FIELD_NUMBER = 5
  val NOTFOUND_OK_FIELD_NUMBER = 6
  val IF_MODIFIED_FIELD_NUMBER = 7
  val HEAD_FIELD_NUMBER = 8
  val DELETEDVCLOCK_FIELD_NUMBER = 9
  val TIMEOUT_FIELD_NUMBER = 10
  val SLOPPY_QUORUM_FIELD_NUMBER = 11
  val N_VAL_FIELD_NUMBER = 12
  val TYPE_FIELD_NUMBER = 13

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbGetReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbGetResp(
  `content`: scala.collection.immutable.Seq[RpbContent] = Vector.empty[RpbContent],
  `vclock`: Option[com.google.protobuf.ByteString] = None,
  `unchanged`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbGetResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbGetResp] {

  def setContent(_i: Int, _v: RpbContent) = copy(`content` = `content`.updated(_i, _v))
  def addContent(_f: RpbContent) = copy(`content` = `content` :+ _f)
  def addAllContent(_f: RpbContent*) = copy(`content` = `content` ++ _f)
  def addAllContent(_f: TraversableOnce[RpbContent]) = copy(`content` = `content` ++ _f)
  def setVclock(_f: com.google.protobuf.ByteString) = copy(`vclock` = Some(_f))
  def setUnchanged(_f: Boolean) = copy(`unchanged` = Some(_f))

  def clearContent = copy(`content` = Vector.empty[RpbContent])
  def clearVclock = copy(`vclock` = None)
  def clearUnchanged = copy(`unchanged` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `content`) output.writeMessage(1, _v)
    if (`vclock`.isDefined) output.writeBytes(2, `vclock`.get)
    if (`unchanged`.isDefined) output.writeBool(3, `unchanged`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `content`) __size += computeMessageSize(1, _v)
    if (`vclock`.isDefined) __size += computeBytesSize(2, `vclock`.get)
    if (`unchanged`.isDefined) __size += computeBoolSize(3, `unchanged`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbGetResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __content: scala.collection.mutable.Buffer[RpbContent] = `content`.toBuffer
    var __vclock: Option[com.google.protobuf.ByteString] = `vclock`
    var __unchanged: Option[Boolean] = `unchanged`

      def __newMerged = RpbGetResp(
        Vector(__content: _*),
        __vclock,
        __unchanged)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __content += readMessage[RpbContent](in, RpbContent.defaultInstance, _emptyRegistry)
      case 18      ⇒ __vclock = Some(in.readBytes())
      case 24      ⇒ __unchanged = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbGetResp) = {
    RpbGetResp(
      `content` ++ m.`content`,
      m.`vclock`.orElse(`vclock`),
      m.`unchanged`.orElse(`unchanged`))
  }

  def getDefaultInstanceForType = RpbGetResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbGetResp {
  @beans.BeanProperty val defaultInstance = new RpbGetResp()

  def parseFrom(data: Array[Byte]): RpbGetResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbGetResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbGetResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbGetResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbGetResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val CONTENT_FIELD_NUMBER = 1
  val VCLOCK_FIELD_NUMBER = 2
  val UNCHANGED_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbGetResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbPutReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: Option[com.google.protobuf.ByteString] = None,
  `vclock`: Option[com.google.protobuf.ByteString] = None,
  `content`: RpbContent = RpbContent.defaultInstance,
  `w`: Option[Int] = None,
  `dw`: Option[Int] = None,
  `returnBody`: Option[Boolean] = None,
  `pw`: Option[Int] = None,
  `ifNotModified`: Option[Boolean] = None,
  `ifNoneMatch`: Option[Boolean] = None,
  `returnHead`: Option[Boolean] = None,
  `timeout`: Option[Int] = None,
  `asis`: Option[Boolean] = None,
  `sloppyQuorum`: Option[Boolean] = None,
  `nVal`: Option[Int] = None,
  `type`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbPutReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbPutReq] {

  def setKey(_f: com.google.protobuf.ByteString) = copy(`key` = Some(_f))
  def setVclock(_f: com.google.protobuf.ByteString) = copy(`vclock` = Some(_f))
  def setW(_f: Int) = copy(`w` = Some(_f))
  def setDw(_f: Int) = copy(`dw` = Some(_f))
  def setReturnBody(_f: Boolean) = copy(`returnBody` = Some(_f))
  def setPw(_f: Int) = copy(`pw` = Some(_f))
  def setIfNotModified(_f: Boolean) = copy(`ifNotModified` = Some(_f))
  def setIfNoneMatch(_f: Boolean) = copy(`ifNoneMatch` = Some(_f))
  def setReturnHead(_f: Boolean) = copy(`returnHead` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setAsis(_f: Boolean) = copy(`asis` = Some(_f))
  def setSloppyQuorum(_f: Boolean) = copy(`sloppyQuorum` = Some(_f))
  def setNVal(_f: Int) = copy(`nVal` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))

  def clearKey = copy(`key` = None)
  def clearVclock = copy(`vclock` = None)
  def clearW = copy(`w` = None)
  def clearDw = copy(`dw` = None)
  def clearReturnBody = copy(`returnBody` = None)
  def clearPw = copy(`pw` = None)
  def clearIfNotModified = copy(`ifNotModified` = None)
  def clearIfNoneMatch = copy(`ifNoneMatch` = None)
  def clearReturnHead = copy(`returnHead` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearAsis = copy(`asis` = None)
  def clearSloppyQuorum = copy(`sloppyQuorum` = None)
  def clearNVal = copy(`nVal` = None)
  def clearType = copy(`type` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    if (`key`.isDefined) output.writeBytes(2, `key`.get)
    if (`vclock`.isDefined) output.writeBytes(3, `vclock`.get)
    output.writeMessage(4, `content`)
    if (`w`.isDefined) output.writeUInt32(5, `w`.get)
    if (`dw`.isDefined) output.writeUInt32(6, `dw`.get)
    if (`returnBody`.isDefined) output.writeBool(7, `returnBody`.get)
    if (`pw`.isDefined) output.writeUInt32(8, `pw`.get)
    if (`ifNotModified`.isDefined) output.writeBool(9, `ifNotModified`.get)
    if (`ifNoneMatch`.isDefined) output.writeBool(10, `ifNoneMatch`.get)
    if (`returnHead`.isDefined) output.writeBool(11, `returnHead`.get)
    if (`timeout`.isDefined) output.writeUInt32(12, `timeout`.get)
    if (`asis`.isDefined) output.writeBool(13, `asis`.get)
    if (`sloppyQuorum`.isDefined) output.writeBool(14, `sloppyQuorum`.get)
    if (`nVal`.isDefined) output.writeUInt32(15, `nVal`.get)
    if (`type`.isDefined) output.writeBytes(16, `type`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    if (`key`.isDefined) __size += computeBytesSize(2, `key`.get)
    if (`vclock`.isDefined) __size += computeBytesSize(3, `vclock`.get)
    __size += computeMessageSize(4, `content`)
    if (`w`.isDefined) __size += computeUInt32Size(5, `w`.get)
    if (`dw`.isDefined) __size += computeUInt32Size(6, `dw`.get)
    if (`returnBody`.isDefined) __size += computeBoolSize(7, `returnBody`.get)
    if (`pw`.isDefined) __size += computeUInt32Size(8, `pw`.get)
    if (`ifNotModified`.isDefined) __size += computeBoolSize(9, `ifNotModified`.get)
    if (`ifNoneMatch`.isDefined) __size += computeBoolSize(10, `ifNoneMatch`.get)
    if (`returnHead`.isDefined) __size += computeBoolSize(11, `returnHead`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(12, `timeout`.get)
    if (`asis`.isDefined) __size += computeBoolSize(13, `asis`.get)
    if (`sloppyQuorum`.isDefined) __size += computeBoolSize(14, `sloppyQuorum`.get)
    if (`nVal`.isDefined) __size += computeUInt32Size(15, `nVal`.get)
    if (`type`.isDefined) __size += computeBytesSize(16, `type`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbPutReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: Option[com.google.protobuf.ByteString] = `key`
    var __vclock: Option[com.google.protobuf.ByteString] = `vclock`
    var __content: RpbContent = RpbContent.defaultInstance
    var __w: Option[Int] = `w`
    var __dw: Option[Int] = `dw`
    var __returnBody: Option[Boolean] = `returnBody`
    var __pw: Option[Int] = `pw`
    var __ifNotModified: Option[Boolean] = `ifNotModified`
    var __ifNoneMatch: Option[Boolean] = `ifNoneMatch`
    var __returnHead: Option[Boolean] = `returnHead`
    var __timeout: Option[Int] = `timeout`
    var __asis: Option[Boolean] = `asis`
    var __sloppyQuorum: Option[Boolean] = `sloppyQuorum`
    var __nVal: Option[Int] = `nVal`
    var __type: Option[com.google.protobuf.ByteString] = `type`

      def __newMerged = RpbPutReq(
        __bucket,
        __key,
        __vclock,
        __content,
        __w,
        __dw,
        __returnBody,
        __pw,
        __ifNotModified,
        __ifNoneMatch,
        __returnHead,
        __timeout,
        __asis,
        __sloppyQuorum,
        __nVal,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = Some(in.readBytes())
      case 26      ⇒ __vclock = Some(in.readBytes())
      case 34      ⇒ __content = readMessage[RpbContent](in, __content, _emptyRegistry)
      case 40      ⇒ __w = Some(in.readUInt32())
      case 48      ⇒ __dw = Some(in.readUInt32())
      case 56      ⇒ __returnBody = Some(in.readBool())
      case 64      ⇒ __pw = Some(in.readUInt32())
      case 72      ⇒ __ifNotModified = Some(in.readBool())
      case 80      ⇒ __ifNoneMatch = Some(in.readBool())
      case 88      ⇒ __returnHead = Some(in.readBool())
      case 96      ⇒ __timeout = Some(in.readUInt32())
      case 104     ⇒ __asis = Some(in.readBool())
      case 112     ⇒ __sloppyQuorum = Some(in.readBool())
      case 120     ⇒ __nVal = Some(in.readUInt32())
      case 130     ⇒ __type = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbPutReq) = {
    RpbPutReq(
      m.`bucket`,
      m.`key`.orElse(`key`),
      m.`vclock`.orElse(`vclock`),
      m.`content`,
      m.`w`.orElse(`w`),
      m.`dw`.orElse(`dw`),
      m.`returnBody`.orElse(`returnBody`),
      m.`pw`.orElse(`pw`),
      m.`ifNotModified`.orElse(`ifNotModified`),
      m.`ifNoneMatch`.orElse(`ifNoneMatch`),
      m.`returnHead`.orElse(`returnHead`),
      m.`timeout`.orElse(`timeout`),
      m.`asis`.orElse(`asis`),
      m.`sloppyQuorum`.orElse(`sloppyQuorum`),
      m.`nVal`.orElse(`nVal`),
      m.`type`.orElse(`type`))
  }

  def getDefaultInstanceForType = RpbPutReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbPutReq {
  @beans.BeanProperty val defaultInstance = new RpbPutReq()

  def parseFrom(data: Array[Byte]): RpbPutReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbPutReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbPutReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbPutReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbPutReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val VCLOCK_FIELD_NUMBER = 3
  val CONTENT_FIELD_NUMBER = 4
  val W_FIELD_NUMBER = 5
  val DW_FIELD_NUMBER = 6
  val RETURN_BODY_FIELD_NUMBER = 7
  val PW_FIELD_NUMBER = 8
  val IF_NOT_MODIFIED_FIELD_NUMBER = 9
  val IF_NONE_MATCH_FIELD_NUMBER = 10
  val RETURN_HEAD_FIELD_NUMBER = 11
  val TIMEOUT_FIELD_NUMBER = 12
  val ASIS_FIELD_NUMBER = 13
  val SLOPPY_QUORUM_FIELD_NUMBER = 14
  val N_VAL_FIELD_NUMBER = 15
  val TYPE_FIELD_NUMBER = 16

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbPutReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbPutResp(
  `content`: scala.collection.immutable.Seq[RpbContent] = Vector.empty[RpbContent],
  `vclock`: Option[com.google.protobuf.ByteString] = None,
  `key`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbPutResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbPutResp] {

  def setContent(_i: Int, _v: RpbContent) = copy(`content` = `content`.updated(_i, _v))
  def addContent(_f: RpbContent) = copy(`content` = `content` :+ _f)
  def addAllContent(_f: RpbContent*) = copy(`content` = `content` ++ _f)
  def addAllContent(_f: TraversableOnce[RpbContent]) = copy(`content` = `content` ++ _f)
  def setVclock(_f: com.google.protobuf.ByteString) = copy(`vclock` = Some(_f))
  def setKey(_f: com.google.protobuf.ByteString) = copy(`key` = Some(_f))

  def clearContent = copy(`content` = Vector.empty[RpbContent])
  def clearVclock = copy(`vclock` = None)
  def clearKey = copy(`key` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `content`) output.writeMessage(1, _v)
    if (`vclock`.isDefined) output.writeBytes(2, `vclock`.get)
    if (`key`.isDefined) output.writeBytes(3, `key`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `content`) __size += computeMessageSize(1, _v)
    if (`vclock`.isDefined) __size += computeBytesSize(2, `vclock`.get)
    if (`key`.isDefined) __size += computeBytesSize(3, `key`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbPutResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __content: scala.collection.mutable.Buffer[RpbContent] = `content`.toBuffer
    var __vclock: Option[com.google.protobuf.ByteString] = `vclock`
    var __key: Option[com.google.protobuf.ByteString] = `key`

      def __newMerged = RpbPutResp(
        Vector(__content: _*),
        __vclock,
        __key)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __content += readMessage[RpbContent](in, RpbContent.defaultInstance, _emptyRegistry)
      case 18      ⇒ __vclock = Some(in.readBytes())
      case 26      ⇒ __key = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbPutResp) = {
    RpbPutResp(
      `content` ++ m.`content`,
      m.`vclock`.orElse(`vclock`),
      m.`key`.orElse(`key`))
  }

  def getDefaultInstanceForType = RpbPutResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbPutResp {
  @beans.BeanProperty val defaultInstance = new RpbPutResp()

  def parseFrom(data: Array[Byte]): RpbPutResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbPutResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbPutResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbPutResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbPutResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val CONTENT_FIELD_NUMBER = 1
  val VCLOCK_FIELD_NUMBER = 2
  val KEY_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbPutResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbDelReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `rw`: Option[Int] = None,
  `vclock`: Option[com.google.protobuf.ByteString] = None,
  `r`: Option[Int] = None,
  `w`: Option[Int] = None,
  `pr`: Option[Int] = None,
  `pw`: Option[Int] = None,
  `dw`: Option[Int] = None,
  `timeout`: Option[Int] = None,
  `sloppyQuorum`: Option[Boolean] = None,
  `nVal`: Option[Int] = None,
  `type`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbDelReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbDelReq] {

  def setRw(_f: Int) = copy(`rw` = Some(_f))
  def setVclock(_f: com.google.protobuf.ByteString) = copy(`vclock` = Some(_f))
  def setR(_f: Int) = copy(`r` = Some(_f))
  def setW(_f: Int) = copy(`w` = Some(_f))
  def setPr(_f: Int) = copy(`pr` = Some(_f))
  def setPw(_f: Int) = copy(`pw` = Some(_f))
  def setDw(_f: Int) = copy(`dw` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setSloppyQuorum(_f: Boolean) = copy(`sloppyQuorum` = Some(_f))
  def setNVal(_f: Int) = copy(`nVal` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))

  def clearRw = copy(`rw` = None)
  def clearVclock = copy(`vclock` = None)
  def clearR = copy(`r` = None)
  def clearW = copy(`w` = None)
  def clearPr = copy(`pr` = None)
  def clearPw = copy(`pw` = None)
  def clearDw = copy(`dw` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearSloppyQuorum = copy(`sloppyQuorum` = None)
  def clearNVal = copy(`nVal` = None)
  def clearType = copy(`type` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `key`)
    if (`rw`.isDefined) output.writeUInt32(3, `rw`.get)
    if (`vclock`.isDefined) output.writeBytes(4, `vclock`.get)
    if (`r`.isDefined) output.writeUInt32(5, `r`.get)
    if (`w`.isDefined) output.writeUInt32(6, `w`.get)
    if (`pr`.isDefined) output.writeUInt32(7, `pr`.get)
    if (`pw`.isDefined) output.writeUInt32(8, `pw`.get)
    if (`dw`.isDefined) output.writeUInt32(9, `dw`.get)
    if (`timeout`.isDefined) output.writeUInt32(10, `timeout`.get)
    if (`sloppyQuorum`.isDefined) output.writeBool(11, `sloppyQuorum`.get)
    if (`nVal`.isDefined) output.writeUInt32(12, `nVal`.get)
    if (`type`.isDefined) output.writeBytes(13, `type`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `key`)
    if (`rw`.isDefined) __size += computeUInt32Size(3, `rw`.get)
    if (`vclock`.isDefined) __size += computeBytesSize(4, `vclock`.get)
    if (`r`.isDefined) __size += computeUInt32Size(5, `r`.get)
    if (`w`.isDefined) __size += computeUInt32Size(6, `w`.get)
    if (`pr`.isDefined) __size += computeUInt32Size(7, `pr`.get)
    if (`pw`.isDefined) __size += computeUInt32Size(8, `pw`.get)
    if (`dw`.isDefined) __size += computeUInt32Size(9, `dw`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(10, `timeout`.get)
    if (`sloppyQuorum`.isDefined) __size += computeBoolSize(11, `sloppyQuorum`.get)
    if (`nVal`.isDefined) __size += computeUInt32Size(12, `nVal`.get)
    if (`type`.isDefined) __size += computeBytesSize(13, `type`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbDelReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __rw: Option[Int] = `rw`
    var __vclock: Option[com.google.protobuf.ByteString] = `vclock`
    var __r: Option[Int] = `r`
    var __w: Option[Int] = `w`
    var __pr: Option[Int] = `pr`
    var __pw: Option[Int] = `pw`
    var __dw: Option[Int] = `dw`
    var __timeout: Option[Int] = `timeout`
    var __sloppyQuorum: Option[Boolean] = `sloppyQuorum`
    var __nVal: Option[Int] = `nVal`
    var __type: Option[com.google.protobuf.ByteString] = `type`

      def __newMerged = RpbDelReq(
        __bucket,
        __key,
        __rw,
        __vclock,
        __r,
        __w,
        __pr,
        __pw,
        __dw,
        __timeout,
        __sloppyQuorum,
        __nVal,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = in.readBytes()
      case 24      ⇒ __rw = Some(in.readUInt32())
      case 34      ⇒ __vclock = Some(in.readBytes())
      case 40      ⇒ __r = Some(in.readUInt32())
      case 48      ⇒ __w = Some(in.readUInt32())
      case 56      ⇒ __pr = Some(in.readUInt32())
      case 64      ⇒ __pw = Some(in.readUInt32())
      case 72      ⇒ __dw = Some(in.readUInt32())
      case 80      ⇒ __timeout = Some(in.readUInt32())
      case 88      ⇒ __sloppyQuorum = Some(in.readBool())
      case 96      ⇒ __nVal = Some(in.readUInt32())
      case 106     ⇒ __type = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbDelReq) = {
    RpbDelReq(
      m.`bucket`,
      m.`key`,
      m.`rw`.orElse(`rw`),
      m.`vclock`.orElse(`vclock`),
      m.`r`.orElse(`r`),
      m.`w`.orElse(`w`),
      m.`pr`.orElse(`pr`),
      m.`pw`.orElse(`pw`),
      m.`dw`.orElse(`dw`),
      m.`timeout`.orElse(`timeout`),
      m.`sloppyQuorum`.orElse(`sloppyQuorum`),
      m.`nVal`.orElse(`nVal`),
      m.`type`.orElse(`type`))
  }

  def getDefaultInstanceForType = RpbDelReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbDelReq {
  @beans.BeanProperty val defaultInstance = new RpbDelReq()

  def parseFrom(data: Array[Byte]): RpbDelReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbDelReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbDelReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbDelReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbDelReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val RW_FIELD_NUMBER = 3
  val VCLOCK_FIELD_NUMBER = 4
  val R_FIELD_NUMBER = 5
  val W_FIELD_NUMBER = 6
  val PR_FIELD_NUMBER = 7
  val PW_FIELD_NUMBER = 8
  val DW_FIELD_NUMBER = 9
  val TIMEOUT_FIELD_NUMBER = 10
  val SLOPPY_QUORUM_FIELD_NUMBER = 11
  val N_VAL_FIELD_NUMBER = 12
  val TYPE_FIELD_NUMBER = 13

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbDelReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbListBucketsReq(
  `timeout`: Option[Int] = None,
  `stream`: Option[Boolean] = None,
  `type`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbListBucketsReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbListBucketsReq] {

  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setStream(_f: Boolean) = copy(`stream` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))

  def clearTimeout = copy(`timeout` = None)
  def clearStream = copy(`stream` = None)
  def clearType = copy(`type` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`timeout`.isDefined) output.writeUInt32(1, `timeout`.get)
    if (`stream`.isDefined) output.writeBool(2, `stream`.get)
    if (`type`.isDefined) output.writeBytes(3, `type`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`timeout`.isDefined) __size += computeUInt32Size(1, `timeout`.get)
    if (`stream`.isDefined) __size += computeBoolSize(2, `stream`.get)
    if (`type`.isDefined) __size += computeBytesSize(3, `type`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbListBucketsReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __timeout: Option[Int] = `timeout`
    var __stream: Option[Boolean] = `stream`
    var __type: Option[com.google.protobuf.ByteString] = `type`

      def __newMerged = RpbListBucketsReq(
        __timeout,
        __stream,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 8       ⇒ __timeout = Some(in.readUInt32())
      case 16      ⇒ __stream = Some(in.readBool())
      case 26      ⇒ __type = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbListBucketsReq) = {
    RpbListBucketsReq(
      m.`timeout`.orElse(`timeout`),
      m.`stream`.orElse(`stream`),
      m.`type`.orElse(`type`))
  }

  def getDefaultInstanceForType = RpbListBucketsReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbListBucketsReq {
  @beans.BeanProperty val defaultInstance = new RpbListBucketsReq()

  def parseFrom(data: Array[Byte]): RpbListBucketsReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbListBucketsReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbListBucketsReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbListBucketsReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbListBucketsReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val TIMEOUT_FIELD_NUMBER = 1
  val STREAM_FIELD_NUMBER = 2
  val TYPE_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbListBucketsReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbListBucketsResp(
  `buckets`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `done`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbListBucketsResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbListBucketsResp] {

  def setBuckets(_i: Int, _v: com.google.protobuf.ByteString) = copy(`buckets` = `buckets`.updated(_i, _v))
  def addBuckets(_f: com.google.protobuf.ByteString) = copy(`buckets` = `buckets` :+ _f)
  def addAllBuckets(_f: com.google.protobuf.ByteString*) = copy(`buckets` = `buckets` ++ _f)
  def addAllBuckets(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`buckets` = `buckets` ++ _f)
  def setDone(_f: Boolean) = copy(`done` = Some(_f))

  def clearBuckets = copy(`buckets` = Vector.empty[com.google.protobuf.ByteString])
  def clearDone = copy(`done` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `buckets`) output.writeBytes(1, _v)
    if (`done`.isDefined) output.writeBool(2, `done`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `buckets`) __size += computeBytesSize(1, _v)
    if (`done`.isDefined) __size += computeBoolSize(2, `done`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbListBucketsResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __buckets: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `buckets`.toBuffer
    var __done: Option[Boolean] = `done`

      def __newMerged = RpbListBucketsResp(
        Vector(__buckets: _*),
        __done)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __buckets += in.readBytes()
      case 16      ⇒ __done = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbListBucketsResp) = {
    RpbListBucketsResp(
      `buckets` ++ m.`buckets`,
      m.`done`.orElse(`done`))
  }

  def getDefaultInstanceForType = RpbListBucketsResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbListBucketsResp {
  @beans.BeanProperty val defaultInstance = new RpbListBucketsResp()

  def parseFrom(data: Array[Byte]): RpbListBucketsResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbListBucketsResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbListBucketsResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbListBucketsResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbListBucketsResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKETS_FIELD_NUMBER = 1
  val DONE_FIELD_NUMBER = 2

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbListBucketsResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbListKeysReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `timeout`: Option[Int] = None,
  `type`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbListKeysReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbListKeysReq] {

  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))

  def clearTimeout = copy(`timeout` = None)
  def clearType = copy(`type` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    if (`timeout`.isDefined) output.writeUInt32(2, `timeout`.get)
    if (`type`.isDefined) output.writeBytes(3, `type`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    if (`timeout`.isDefined) __size += computeUInt32Size(2, `timeout`.get)
    if (`type`.isDefined) __size += computeBytesSize(3, `type`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbListKeysReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __timeout: Option[Int] = `timeout`
    var __type: Option[com.google.protobuf.ByteString] = `type`

      def __newMerged = RpbListKeysReq(
        __bucket,
        __timeout,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 16      ⇒ __timeout = Some(in.readUInt32())
      case 26      ⇒ __type = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbListKeysReq) = {
    RpbListKeysReq(
      m.`bucket`,
      m.`timeout`.orElse(`timeout`),
      m.`type`.orElse(`type`))
  }

  def getDefaultInstanceForType = RpbListKeysReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbListKeysReq {
  @beans.BeanProperty val defaultInstance = new RpbListKeysReq()

  def parseFrom(data: Array[Byte]): RpbListKeysReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbListKeysReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbListKeysReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbListKeysReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbListKeysReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val TIMEOUT_FIELD_NUMBER = 2
  val TYPE_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbListKeysReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbListKeysResp(
  `keys`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `done`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbListKeysResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbListKeysResp] {

  def setKeys(_i: Int, _v: com.google.protobuf.ByteString) = copy(`keys` = `keys`.updated(_i, _v))
  def addKeys(_f: com.google.protobuf.ByteString) = copy(`keys` = `keys` :+ _f)
  def addAllKeys(_f: com.google.protobuf.ByteString*) = copy(`keys` = `keys` ++ _f)
  def addAllKeys(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`keys` = `keys` ++ _f)
  def setDone(_f: Boolean) = copy(`done` = Some(_f))

  def clearKeys = copy(`keys` = Vector.empty[com.google.protobuf.ByteString])
  def clearDone = copy(`done` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `keys`) output.writeBytes(1, _v)
    if (`done`.isDefined) output.writeBool(2, `done`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `keys`) __size += computeBytesSize(1, _v)
    if (`done`.isDefined) __size += computeBoolSize(2, `done`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbListKeysResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __keys: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `keys`.toBuffer
    var __done: Option[Boolean] = `done`

      def __newMerged = RpbListKeysResp(
        Vector(__keys: _*),
        __done)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __keys += in.readBytes()
      case 16      ⇒ __done = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbListKeysResp) = {
    RpbListKeysResp(
      `keys` ++ m.`keys`,
      m.`done`.orElse(`done`))
  }

  def getDefaultInstanceForType = RpbListKeysResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbListKeysResp {
  @beans.BeanProperty val defaultInstance = new RpbListKeysResp()

  def parseFrom(data: Array[Byte]): RpbListKeysResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbListKeysResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbListKeysResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbListKeysResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbListKeysResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val KEYS_FIELD_NUMBER = 1
  val DONE_FIELD_NUMBER = 2

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbListKeysResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbMapRedReq(
  `request`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `contentType`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbMapRedReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbMapRedReq] {

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `request`)
    output.writeBytes(2, `contentType`)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `request`)
    __size += computeBytesSize(2, `contentType`)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbMapRedReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __request: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __contentType: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY

      def __newMerged = RpbMapRedReq(
        __request,
        __contentType)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __request = in.readBytes()
      case 18      ⇒ __contentType = in.readBytes()
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbMapRedReq) = {
    RpbMapRedReq(
      m.`request`,
      m.`contentType`)
  }

  def getDefaultInstanceForType = RpbMapRedReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbMapRedReq {
  @beans.BeanProperty val defaultInstance = new RpbMapRedReq()

  def parseFrom(data: Array[Byte]): RpbMapRedReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbMapRedReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbMapRedReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbMapRedReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbMapRedReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val REQUEST_FIELD_NUMBER = 1
  val CONTENT_TYPE_FIELD_NUMBER = 2

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbMapRedReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbMapRedResp(
  `phase`: Option[Int] = None,
  `response`: Option[com.google.protobuf.ByteString] = None,
  `done`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbMapRedResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbMapRedResp] {

  def setPhase(_f: Int) = copy(`phase` = Some(_f))
  def setResponse(_f: com.google.protobuf.ByteString) = copy(`response` = Some(_f))
  def setDone(_f: Boolean) = copy(`done` = Some(_f))

  def clearPhase = copy(`phase` = None)
  def clearResponse = copy(`response` = None)
  def clearDone = copy(`done` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`phase`.isDefined) output.writeUInt32(1, `phase`.get)
    if (`response`.isDefined) output.writeBytes(2, `response`.get)
    if (`done`.isDefined) output.writeBool(3, `done`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`phase`.isDefined) __size += computeUInt32Size(1, `phase`.get)
    if (`response`.isDefined) __size += computeBytesSize(2, `response`.get)
    if (`done`.isDefined) __size += computeBoolSize(3, `done`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbMapRedResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __phase: Option[Int] = `phase`
    var __response: Option[com.google.protobuf.ByteString] = `response`
    var __done: Option[Boolean] = `done`

      def __newMerged = RpbMapRedResp(
        __phase,
        __response,
        __done)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 8       ⇒ __phase = Some(in.readUInt32())
      case 18      ⇒ __response = Some(in.readBytes())
      case 24      ⇒ __done = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbMapRedResp) = {
    RpbMapRedResp(
      m.`phase`.orElse(`phase`),
      m.`response`.orElse(`response`),
      m.`done`.orElse(`done`))
  }

  def getDefaultInstanceForType = RpbMapRedResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbMapRedResp {
  @beans.BeanProperty val defaultInstance = new RpbMapRedResp()

  def parseFrom(data: Array[Byte]): RpbMapRedResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbMapRedResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbMapRedResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbMapRedResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbMapRedResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val PHASE_FIELD_NUMBER = 1
  val RESPONSE_FIELD_NUMBER = 2
  val DONE_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbMapRedResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbIndexReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `index`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `qtype`: RpbIndexReq.IndexQueryType.EnumVal = RpbIndexReq.IndexQueryType._UNINITIALIZED,
  `key`: Option[com.google.protobuf.ByteString] = None,
  `rangeMin`: Option[com.google.protobuf.ByteString] = None,
  `rangeMax`: Option[com.google.protobuf.ByteString] = None,
  `returnTerms`: Option[Boolean] = None,
  `stream`: Option[Boolean] = None,
  `maxResults`: Option[Int] = None,
  `continuation`: Option[com.google.protobuf.ByteString] = None,
  `timeout`: Option[Int] = None,
  `type`: Option[com.google.protobuf.ByteString] = None,
  `termRegex`: Option[com.google.protobuf.ByteString] = None,
  `paginationSort`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbIndexReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbIndexReq] {

  def setKey(_f: com.google.protobuf.ByteString) = copy(`key` = Some(_f))
  def setRangeMin(_f: com.google.protobuf.ByteString) = copy(`rangeMin` = Some(_f))
  def setRangeMax(_f: com.google.protobuf.ByteString) = copy(`rangeMax` = Some(_f))
  def setReturnTerms(_f: Boolean) = copy(`returnTerms` = Some(_f))
  def setStream(_f: Boolean) = copy(`stream` = Some(_f))
  def setMaxResults(_f: Int) = copy(`maxResults` = Some(_f))
  def setContinuation(_f: com.google.protobuf.ByteString) = copy(`continuation` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))
  def setTermRegex(_f: com.google.protobuf.ByteString) = copy(`termRegex` = Some(_f))
  def setPaginationSort(_f: Boolean) = copy(`paginationSort` = Some(_f))

  def clearKey = copy(`key` = None)
  def clearRangeMin = copy(`rangeMin` = None)
  def clearRangeMax = copy(`rangeMax` = None)
  def clearReturnTerms = copy(`returnTerms` = None)
  def clearStream = copy(`stream` = None)
  def clearMaxResults = copy(`maxResults` = None)
  def clearContinuation = copy(`continuation` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearType = copy(`type` = None)
  def clearTermRegex = copy(`termRegex` = None)
  def clearPaginationSort = copy(`paginationSort` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `index`)
    output.writeEnum(3, `qtype`)
    if (`key`.isDefined) output.writeBytes(4, `key`.get)
    if (`rangeMin`.isDefined) output.writeBytes(5, `rangeMin`.get)
    if (`rangeMax`.isDefined) output.writeBytes(6, `rangeMax`.get)
    if (`returnTerms`.isDefined) output.writeBool(7, `returnTerms`.get)
    if (`stream`.isDefined) output.writeBool(8, `stream`.get)
    if (`maxResults`.isDefined) output.writeUInt32(9, `maxResults`.get)
    if (`continuation`.isDefined) output.writeBytes(10, `continuation`.get)
    if (`timeout`.isDefined) output.writeUInt32(11, `timeout`.get)
    if (`type`.isDefined) output.writeBytes(12, `type`.get)
    if (`termRegex`.isDefined) output.writeBytes(13, `termRegex`.get)
    if (`paginationSort`.isDefined) output.writeBool(14, `paginationSort`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `index`)
    __size += computeEnumSize(3, `qtype`)
    if (`key`.isDefined) __size += computeBytesSize(4, `key`.get)
    if (`rangeMin`.isDefined) __size += computeBytesSize(5, `rangeMin`.get)
    if (`rangeMax`.isDefined) __size += computeBytesSize(6, `rangeMax`.get)
    if (`returnTerms`.isDefined) __size += computeBoolSize(7, `returnTerms`.get)
    if (`stream`.isDefined) __size += computeBoolSize(8, `stream`.get)
    if (`maxResults`.isDefined) __size += computeUInt32Size(9, `maxResults`.get)
    if (`continuation`.isDefined) __size += computeBytesSize(10, `continuation`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(11, `timeout`.get)
    if (`type`.isDefined) __size += computeBytesSize(12, `type`.get)
    if (`termRegex`.isDefined) __size += computeBytesSize(13, `termRegex`.get)
    if (`paginationSort`.isDefined) __size += computeBoolSize(14, `paginationSort`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbIndexReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __index: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __qtype: RpbIndexReq.IndexQueryType.EnumVal = RpbIndexReq.IndexQueryType._UNINITIALIZED
    var __key: Option[com.google.protobuf.ByteString] = `key`
    var __rangeMin: Option[com.google.protobuf.ByteString] = `rangeMin`
    var __rangeMax: Option[com.google.protobuf.ByteString] = `rangeMax`
    var __returnTerms: Option[Boolean] = `returnTerms`
    var __stream: Option[Boolean] = `stream`
    var __maxResults: Option[Int] = `maxResults`
    var __continuation: Option[com.google.protobuf.ByteString] = `continuation`
    var __timeout: Option[Int] = `timeout`
    var __type: Option[com.google.protobuf.ByteString] = `type`
    var __termRegex: Option[com.google.protobuf.ByteString] = `termRegex`
    var __paginationSort: Option[Boolean] = `paginationSort`

      def __newMerged = RpbIndexReq(
        __bucket,
        __index,
        __qtype,
        __key,
        __rangeMin,
        __rangeMax,
        __returnTerms,
        __stream,
        __maxResults,
        __continuation,
        __timeout,
        __type,
        __termRegex,
        __paginationSort)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __index = in.readBytes()
      case 24      ⇒ __qtype = RpbIndexReq.IndexQueryType.valueOf(in.readEnum())
      case 34      ⇒ __key = Some(in.readBytes())
      case 42      ⇒ __rangeMin = Some(in.readBytes())
      case 50      ⇒ __rangeMax = Some(in.readBytes())
      case 56      ⇒ __returnTerms = Some(in.readBool())
      case 64      ⇒ __stream = Some(in.readBool())
      case 72      ⇒ __maxResults = Some(in.readUInt32())
      case 82      ⇒ __continuation = Some(in.readBytes())
      case 88      ⇒ __timeout = Some(in.readUInt32())
      case 98      ⇒ __type = Some(in.readBytes())
      case 106     ⇒ __termRegex = Some(in.readBytes())
      case 112     ⇒ __paginationSort = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbIndexReq) = {
    RpbIndexReq(
      m.`bucket`,
      m.`index`,
      m.`qtype`,
      m.`key`.orElse(`key`),
      m.`rangeMin`.orElse(`rangeMin`),
      m.`rangeMax`.orElse(`rangeMax`),
      m.`returnTerms`.orElse(`returnTerms`),
      m.`stream`.orElse(`stream`),
      m.`maxResults`.orElse(`maxResults`),
      m.`continuation`.orElse(`continuation`),
      m.`timeout`.orElse(`timeout`),
      m.`type`.orElse(`type`),
      m.`termRegex`.orElse(`termRegex`),
      m.`paginationSort`.orElse(`paginationSort`))
  }

  def getDefaultInstanceForType = RpbIndexReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbIndexReq {
  @beans.BeanProperty val defaultInstance = new RpbIndexReq()

  def parseFrom(data: Array[Byte]): RpbIndexReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbIndexReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbIndexReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbIndexReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbIndexReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val INDEX_FIELD_NUMBER = 2
  val QTYPE_FIELD_NUMBER = 3
  val KEY_FIELD_NUMBER = 4
  val RANGE_MIN_FIELD_NUMBER = 5
  val RANGE_MAX_FIELD_NUMBER = 6
  val RETURN_TERMS_FIELD_NUMBER = 7
  val STREAM_FIELD_NUMBER = 8
  val MAX_RESULTS_FIELD_NUMBER = 9
  val CONTINUATION_FIELD_NUMBER = 10
  val TIMEOUT_FIELD_NUMBER = 11
  val TYPE_FIELD_NUMBER = 12
  val TERM_REGEX_FIELD_NUMBER = 13
  val PAGINATION_SORT_FIELD_NUMBER = 14

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbIndexReq) = defaultInstance.mergeFrom(prototype)

  object IndexQueryType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val eq = new EnumVal { val name = "eq"; val id = 0 }
    val range = new EnumVal { val name = "range"; val id = 1 }

    val eq_VALUE = 0
    val range_VALUE = 1

    def valueOf(id: Int) = id match {
      case 0        ⇒ eq
      case 1        ⇒ range
      case _default ⇒ throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class RpbIndexResp(
  `keys`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `results`: scala.collection.immutable.Seq[com.basho.riak.protobuf.RpbPair] = Vector.empty[com.basho.riak.protobuf.RpbPair],
  `continuation`: Option[com.google.protobuf.ByteString] = None,
  `done`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbIndexResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbIndexResp] {

  def setKeys(_i: Int, _v: com.google.protobuf.ByteString) = copy(`keys` = `keys`.updated(_i, _v))
  def addKeys(_f: com.google.protobuf.ByteString) = copy(`keys` = `keys` :+ _f)
  def addAllKeys(_f: com.google.protobuf.ByteString*) = copy(`keys` = `keys` ++ _f)
  def addAllKeys(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`keys` = `keys` ++ _f)
  def setResults(_i: Int, _v: com.basho.riak.protobuf.RpbPair) = copy(`results` = `results`.updated(_i, _v))
  def addResults(_f: com.basho.riak.protobuf.RpbPair) = copy(`results` = `results` :+ _f)
  def addAllResults(_f: com.basho.riak.protobuf.RpbPair*) = copy(`results` = `results` ++ _f)
  def addAllResults(_f: TraversableOnce[com.basho.riak.protobuf.RpbPair]) = copy(`results` = `results` ++ _f)
  def setContinuation(_f: com.google.protobuf.ByteString) = copy(`continuation` = Some(_f))
  def setDone(_f: Boolean) = copy(`done` = Some(_f))

  def clearKeys = copy(`keys` = Vector.empty[com.google.protobuf.ByteString])
  def clearResults = copy(`results` = Vector.empty[com.basho.riak.protobuf.RpbPair])
  def clearContinuation = copy(`continuation` = None)
  def clearDone = copy(`done` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `keys`) output.writeBytes(1, _v)
    for (_v ← `results`) output.writeMessage(2, _v)
    if (`continuation`.isDefined) output.writeBytes(3, `continuation`.get)
    if (`done`.isDefined) output.writeBool(4, `done`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `keys`) __size += computeBytesSize(1, _v)
    for (_v ← `results`) __size += computeMessageSize(2, _v)
    if (`continuation`.isDefined) __size += computeBytesSize(3, `continuation`.get)
    if (`done`.isDefined) __size += computeBoolSize(4, `done`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbIndexResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __keys: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `keys`.toBuffer
    val __results: scala.collection.mutable.Buffer[com.basho.riak.protobuf.RpbPair] = `results`.toBuffer
    var __continuation: Option[com.google.protobuf.ByteString] = `continuation`
    var __done: Option[Boolean] = `done`

      def __newMerged = RpbIndexResp(
        Vector(__keys: _*),
        Vector(__results: _*),
        __continuation,
        __done)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __keys += in.readBytes()
      case 18      ⇒ __results += readMessage[com.basho.riak.protobuf.RpbPair](in, com.basho.riak.protobuf.RpbPair.defaultInstance, _emptyRegistry)
      case 26      ⇒ __continuation = Some(in.readBytes())
      case 32      ⇒ __done = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbIndexResp) = {
    RpbIndexResp(
      `keys` ++ m.`keys`,
      `results` ++ m.`results`,
      m.`continuation`.orElse(`continuation`),
      m.`done`.orElse(`done`))
  }

  def getDefaultInstanceForType = RpbIndexResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbIndexResp {
  @beans.BeanProperty val defaultInstance = new RpbIndexResp()

  def parseFrom(data: Array[Byte]): RpbIndexResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbIndexResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbIndexResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbIndexResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbIndexResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val KEYS_FIELD_NUMBER = 1
  val RESULTS_FIELD_NUMBER = 2
  val CONTINUATION_FIELD_NUMBER = 3
  val DONE_FIELD_NUMBER = 4

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbIndexResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbCSBucketReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `startKey`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `endKey`: Option[com.google.protobuf.ByteString] = None,
  `startIncl`: Option[Boolean] = Some(true),
  `endIncl`: Option[Boolean] = Some(false),
  `continuation`: Option[com.google.protobuf.ByteString] = None,
  `maxResults`: Option[Int] = None,
  `timeout`: Option[Int] = None,
  `type`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbCSBucketReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbCSBucketReq] {

  def setEndKey(_f: com.google.protobuf.ByteString) = copy(`endKey` = Some(_f))
  def setStartIncl(_f: Boolean) = copy(`startIncl` = Some(_f))
  def setEndIncl(_f: Boolean) = copy(`endIncl` = Some(_f))
  def setContinuation(_f: com.google.protobuf.ByteString) = copy(`continuation` = Some(_f))
  def setMaxResults(_f: Int) = copy(`maxResults` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setType(_f: com.google.protobuf.ByteString) = copy(`type` = Some(_f))

  def clearEndKey = copy(`endKey` = None)
  def clearStartIncl = copy(`startIncl` = None)
  def clearEndIncl = copy(`endIncl` = None)
  def clearContinuation = copy(`continuation` = None)
  def clearMaxResults = copy(`maxResults` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearType = copy(`type` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `startKey`)
    if (`endKey`.isDefined) output.writeBytes(3, `endKey`.get)
    if (`startIncl`.isDefined) output.writeBool(4, `startIncl`.get)
    if (`endIncl`.isDefined) output.writeBool(5, `endIncl`.get)
    if (`continuation`.isDefined) output.writeBytes(6, `continuation`.get)
    if (`maxResults`.isDefined) output.writeUInt32(7, `maxResults`.get)
    if (`timeout`.isDefined) output.writeUInt32(8, `timeout`.get)
    if (`type`.isDefined) output.writeBytes(9, `type`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `startKey`)
    if (`endKey`.isDefined) __size += computeBytesSize(3, `endKey`.get)
    if (`startIncl`.isDefined) __size += computeBoolSize(4, `startIncl`.get)
    if (`endIncl`.isDefined) __size += computeBoolSize(5, `endIncl`.get)
    if (`continuation`.isDefined) __size += computeBytesSize(6, `continuation`.get)
    if (`maxResults`.isDefined) __size += computeUInt32Size(7, `maxResults`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(8, `timeout`.get)
    if (`type`.isDefined) __size += computeBytesSize(9, `type`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbCSBucketReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __startKey: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __endKey: Option[com.google.protobuf.ByteString] = `endKey`
    var __startIncl: Option[Boolean] = `startIncl`
    var __endIncl: Option[Boolean] = `endIncl`
    var __continuation: Option[com.google.protobuf.ByteString] = `continuation`
    var __maxResults: Option[Int] = `maxResults`
    var __timeout: Option[Int] = `timeout`
    var __type: Option[com.google.protobuf.ByteString] = `type`

      def __newMerged = RpbCSBucketReq(
        __bucket,
        __startKey,
        __endKey,
        __startIncl,
        __endIncl,
        __continuation,
        __maxResults,
        __timeout,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __startKey = in.readBytes()
      case 26      ⇒ __endKey = Some(in.readBytes())
      case 32      ⇒ __startIncl = Some(in.readBool())
      case 40      ⇒ __endIncl = Some(in.readBool())
      case 50      ⇒ __continuation = Some(in.readBytes())
      case 56      ⇒ __maxResults = Some(in.readUInt32())
      case 64      ⇒ __timeout = Some(in.readUInt32())
      case 74      ⇒ __type = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbCSBucketReq) = {
    RpbCSBucketReq(
      m.`bucket`,
      m.`startKey`,
      m.`endKey`.orElse(`endKey`),
      m.`startIncl`.orElse(`startIncl`),
      m.`endIncl`.orElse(`endIncl`),
      m.`continuation`.orElse(`continuation`),
      m.`maxResults`.orElse(`maxResults`),
      m.`timeout`.orElse(`timeout`),
      m.`type`.orElse(`type`))
  }

  def getDefaultInstanceForType = RpbCSBucketReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbCSBucketReq {
  @beans.BeanProperty val defaultInstance = new RpbCSBucketReq()

  def parseFrom(data: Array[Byte]): RpbCSBucketReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbCSBucketReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbCSBucketReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbCSBucketReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbCSBucketReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val START_KEY_FIELD_NUMBER = 2
  val END_KEY_FIELD_NUMBER = 3
  val START_INCL_FIELD_NUMBER = 4
  val END_INCL_FIELD_NUMBER = 5
  val CONTINUATION_FIELD_NUMBER = 6
  val MAX_RESULTS_FIELD_NUMBER = 7
  val TIMEOUT_FIELD_NUMBER = 8
  val TYPE_FIELD_NUMBER = 9

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbCSBucketReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbCSBucketResp(
  `objects`: scala.collection.immutable.Seq[RpbIndexObject] = Vector.empty[RpbIndexObject],
  `continuation`: Option[com.google.protobuf.ByteString] = None,
  `done`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbCSBucketResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbCSBucketResp] {

  def setObjects(_i: Int, _v: RpbIndexObject) = copy(`objects` = `objects`.updated(_i, _v))
  def addObjects(_f: RpbIndexObject) = copy(`objects` = `objects` :+ _f)
  def addAllObjects(_f: RpbIndexObject*) = copy(`objects` = `objects` ++ _f)
  def addAllObjects(_f: TraversableOnce[RpbIndexObject]) = copy(`objects` = `objects` ++ _f)
  def setContinuation(_f: com.google.protobuf.ByteString) = copy(`continuation` = Some(_f))
  def setDone(_f: Boolean) = copy(`done` = Some(_f))

  def clearObjects = copy(`objects` = Vector.empty[RpbIndexObject])
  def clearContinuation = copy(`continuation` = None)
  def clearDone = copy(`done` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `objects`) output.writeMessage(1, _v)
    if (`continuation`.isDefined) output.writeBytes(2, `continuation`.get)
    if (`done`.isDefined) output.writeBool(3, `done`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `objects`) __size += computeMessageSize(1, _v)
    if (`continuation`.isDefined) __size += computeBytesSize(2, `continuation`.get)
    if (`done`.isDefined) __size += computeBoolSize(3, `done`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbCSBucketResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __objects: scala.collection.mutable.Buffer[RpbIndexObject] = `objects`.toBuffer
    var __continuation: Option[com.google.protobuf.ByteString] = `continuation`
    var __done: Option[Boolean] = `done`

      def __newMerged = RpbCSBucketResp(
        Vector(__objects: _*),
        __continuation,
        __done)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __objects += readMessage[RpbIndexObject](in, RpbIndexObject.defaultInstance, _emptyRegistry)
      case 18      ⇒ __continuation = Some(in.readBytes())
      case 24      ⇒ __done = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbCSBucketResp) = {
    RpbCSBucketResp(
      `objects` ++ m.`objects`,
      m.`continuation`.orElse(`continuation`),
      m.`done`.orElse(`done`))
  }

  def getDefaultInstanceForType = RpbCSBucketResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbCSBucketResp {
  @beans.BeanProperty val defaultInstance = new RpbCSBucketResp()

  def parseFrom(data: Array[Byte]): RpbCSBucketResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbCSBucketResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbCSBucketResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbCSBucketResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbCSBucketResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val OBJECTS_FIELD_NUMBER = 1
  val CONTINUATION_FIELD_NUMBER = 2
  val DONE_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbCSBucketResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbIndexObject(
  `key`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `object`: RpbGetResp = RpbGetResp.defaultInstance) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbIndexObject]
    with net.sandrogrzicic.scalabuff.Parser[RpbIndexObject] {

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `key`)
    output.writeMessage(2, `object`)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `key`)
    __size += computeMessageSize(2, `object`)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbIndexObject = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __key: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __object: RpbGetResp = RpbGetResp.defaultInstance

      def __newMerged = RpbIndexObject(
        __key,
        __object)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __key = in.readBytes()
      case 18      ⇒ __object = readMessage[RpbGetResp](in, __object, _emptyRegistry)
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbIndexObject) = {
    RpbIndexObject(
      m.`key`,
      m.`object`)
  }

  def getDefaultInstanceForType = RpbIndexObject.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbIndexObject {
  @beans.BeanProperty val defaultInstance = new RpbIndexObject()

  def parseFrom(data: Array[Byte]): RpbIndexObject = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbIndexObject = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbIndexObject = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbIndexObject = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbIndexObject] = defaultInstance.mergeDelimitedFromStream(stream)

  val KEY_FIELD_NUMBER = 1
  val OBJECT_FIELD_NUMBER = 2

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbIndexObject) = defaultInstance.mergeFrom(prototype)

}
final case class RpbContent(
  `value`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `contentType`: Option[com.google.protobuf.ByteString] = None,
  `charset`: Option[com.google.protobuf.ByteString] = None,
  `contentEncoding`: Option[com.google.protobuf.ByteString] = None,
  `vtag`: Option[com.google.protobuf.ByteString] = None,
  `links`: scala.collection.immutable.Seq[RpbLink] = Vector.empty[RpbLink],
  `lastMod`: Option[Int] = None,
  `lastModUsecs`: Option[Int] = None,
  `usermeta`: scala.collection.immutable.Seq[com.basho.riak.protobuf.RpbPair] = Vector.empty[com.basho.riak.protobuf.RpbPair],
  `indexes`: scala.collection.immutable.Seq[com.basho.riak.protobuf.RpbPair] = Vector.empty[com.basho.riak.protobuf.RpbPair],
  `deleted`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbContent]
    with net.sandrogrzicic.scalabuff.Parser[RpbContent] {

  def setContentType(_f: com.google.protobuf.ByteString) = copy(`contentType` = Some(_f))
  def setCharset(_f: com.google.protobuf.ByteString) = copy(`charset` = Some(_f))
  def setContentEncoding(_f: com.google.protobuf.ByteString) = copy(`contentEncoding` = Some(_f))
  def setVtag(_f: com.google.protobuf.ByteString) = copy(`vtag` = Some(_f))
  def setLinks(_i: Int, _v: RpbLink) = copy(`links` = `links`.updated(_i, _v))
  def addLinks(_f: RpbLink) = copy(`links` = `links` :+ _f)
  def addAllLinks(_f: RpbLink*) = copy(`links` = `links` ++ _f)
  def addAllLinks(_f: TraversableOnce[RpbLink]) = copy(`links` = `links` ++ _f)
  def setLastMod(_f: Int) = copy(`lastMod` = Some(_f))
  def setLastModUsecs(_f: Int) = copy(`lastModUsecs` = Some(_f))
  def setUsermeta(_i: Int, _v: com.basho.riak.protobuf.RpbPair) = copy(`usermeta` = `usermeta`.updated(_i, _v))
  def addUsermeta(_f: com.basho.riak.protobuf.RpbPair) = copy(`usermeta` = `usermeta` :+ _f)
  def addAllUsermeta(_f: com.basho.riak.protobuf.RpbPair*) = copy(`usermeta` = `usermeta` ++ _f)
  def addAllUsermeta(_f: TraversableOnce[com.basho.riak.protobuf.RpbPair]) = copy(`usermeta` = `usermeta` ++ _f)
  def setIndexes(_i: Int, _v: com.basho.riak.protobuf.RpbPair) = copy(`indexes` = `indexes`.updated(_i, _v))
  def addIndexes(_f: com.basho.riak.protobuf.RpbPair) = copy(`indexes` = `indexes` :+ _f)
  def addAllIndexes(_f: com.basho.riak.protobuf.RpbPair*) = copy(`indexes` = `indexes` ++ _f)
  def addAllIndexes(_f: TraversableOnce[com.basho.riak.protobuf.RpbPair]) = copy(`indexes` = `indexes` ++ _f)
  def setDeleted(_f: Boolean) = copy(`deleted` = Some(_f))

  def clearContentType = copy(`contentType` = None)
  def clearCharset = copy(`charset` = None)
  def clearContentEncoding = copy(`contentEncoding` = None)
  def clearVtag = copy(`vtag` = None)
  def clearLinks = copy(`links` = Vector.empty[RpbLink])
  def clearLastMod = copy(`lastMod` = None)
  def clearLastModUsecs = copy(`lastModUsecs` = None)
  def clearUsermeta = copy(`usermeta` = Vector.empty[com.basho.riak.protobuf.RpbPair])
  def clearIndexes = copy(`indexes` = Vector.empty[com.basho.riak.protobuf.RpbPair])
  def clearDeleted = copy(`deleted` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `value`)
    if (`contentType`.isDefined) output.writeBytes(2, `contentType`.get)
    if (`charset`.isDefined) output.writeBytes(3, `charset`.get)
    if (`contentEncoding`.isDefined) output.writeBytes(4, `contentEncoding`.get)
    if (`vtag`.isDefined) output.writeBytes(5, `vtag`.get)
    for (_v ← `links`) output.writeMessage(6, _v)
    if (`lastMod`.isDefined) output.writeUInt32(7, `lastMod`.get)
    if (`lastModUsecs`.isDefined) output.writeUInt32(8, `lastModUsecs`.get)
    for (_v ← `usermeta`) output.writeMessage(9, _v)
    for (_v ← `indexes`) output.writeMessage(10, _v)
    if (`deleted`.isDefined) output.writeBool(11, `deleted`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `value`)
    if (`contentType`.isDefined) __size += computeBytesSize(2, `contentType`.get)
    if (`charset`.isDefined) __size += computeBytesSize(3, `charset`.get)
    if (`contentEncoding`.isDefined) __size += computeBytesSize(4, `contentEncoding`.get)
    if (`vtag`.isDefined) __size += computeBytesSize(5, `vtag`.get)
    for (_v ← `links`) __size += computeMessageSize(6, _v)
    if (`lastMod`.isDefined) __size += computeUInt32Size(7, `lastMod`.get)
    if (`lastModUsecs`.isDefined) __size += computeUInt32Size(8, `lastModUsecs`.get)
    for (_v ← `usermeta`) __size += computeMessageSize(9, _v)
    for (_v ← `indexes`) __size += computeMessageSize(10, _v)
    if (`deleted`.isDefined) __size += computeBoolSize(11, `deleted`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbContent = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __value: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __contentType: Option[com.google.protobuf.ByteString] = `contentType`
    var __charset: Option[com.google.protobuf.ByteString] = `charset`
    var __contentEncoding: Option[com.google.protobuf.ByteString] = `contentEncoding`
    var __vtag: Option[com.google.protobuf.ByteString] = `vtag`
    val __links: scala.collection.mutable.Buffer[RpbLink] = `links`.toBuffer
    var __lastMod: Option[Int] = `lastMod`
    var __lastModUsecs: Option[Int] = `lastModUsecs`
    val __usermeta: scala.collection.mutable.Buffer[com.basho.riak.protobuf.RpbPair] = `usermeta`.toBuffer
    val __indexes: scala.collection.mutable.Buffer[com.basho.riak.protobuf.RpbPair] = `indexes`.toBuffer
    var __deleted: Option[Boolean] = `deleted`

      def __newMerged = RpbContent(
        __value,
        __contentType,
        __charset,
        __contentEncoding,
        __vtag,
        Vector(__links: _*),
        __lastMod,
        __lastModUsecs,
        Vector(__usermeta: _*),
        Vector(__indexes: _*),
        __deleted)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __value = in.readBytes()
      case 18      ⇒ __contentType = Some(in.readBytes())
      case 26      ⇒ __charset = Some(in.readBytes())
      case 34      ⇒ __contentEncoding = Some(in.readBytes())
      case 42      ⇒ __vtag = Some(in.readBytes())
      case 50      ⇒ __links += readMessage[RpbLink](in, RpbLink.defaultInstance, _emptyRegistry)
      case 56      ⇒ __lastMod = Some(in.readUInt32())
      case 64      ⇒ __lastModUsecs = Some(in.readUInt32())
      case 74      ⇒ __usermeta += readMessage[com.basho.riak.protobuf.RpbPair](in, com.basho.riak.protobuf.RpbPair.defaultInstance, _emptyRegistry)
      case 82      ⇒ __indexes += readMessage[com.basho.riak.protobuf.RpbPair](in, com.basho.riak.protobuf.RpbPair.defaultInstance, _emptyRegistry)
      case 88      ⇒ __deleted = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbContent) = {
    RpbContent(
      m.`value`,
      m.`contentType`.orElse(`contentType`),
      m.`charset`.orElse(`charset`),
      m.`contentEncoding`.orElse(`contentEncoding`),
      m.`vtag`.orElse(`vtag`),
      `links` ++ m.`links`,
      m.`lastMod`.orElse(`lastMod`),
      m.`lastModUsecs`.orElse(`lastModUsecs`),
      `usermeta` ++ m.`usermeta`,
      `indexes` ++ m.`indexes`,
      m.`deleted`.orElse(`deleted`))
  }

  def getDefaultInstanceForType = RpbContent.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbContent {
  @beans.BeanProperty val defaultInstance = new RpbContent()

  def parseFrom(data: Array[Byte]): RpbContent = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbContent = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbContent = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbContent = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbContent] = defaultInstance.mergeDelimitedFromStream(stream)

  val VALUE_FIELD_NUMBER = 1
  val CONTENT_TYPE_FIELD_NUMBER = 2
  val CHARSET_FIELD_NUMBER = 3
  val CONTENT_ENCODING_FIELD_NUMBER = 4
  val VTAG_FIELD_NUMBER = 5
  val LINKS_FIELD_NUMBER = 6
  val LAST_MOD_FIELD_NUMBER = 7
  val LAST_MOD_USECS_FIELD_NUMBER = 8
  val USERMETA_FIELD_NUMBER = 9
  val INDEXES_FIELD_NUMBER = 10
  val DELETED_FIELD_NUMBER = 11

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbContent) = defaultInstance.mergeFrom(prototype)

}
final case class RpbLink(
  `bucket`: Option[com.google.protobuf.ByteString] = None,
  `key`: Option[com.google.protobuf.ByteString] = None,
  `tag`: Option[com.google.protobuf.ByteString] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbLink]
    with net.sandrogrzicic.scalabuff.Parser[RpbLink] {

  def setBucket(_f: com.google.protobuf.ByteString) = copy(`bucket` = Some(_f))
  def setKey(_f: com.google.protobuf.ByteString) = copy(`key` = Some(_f))
  def setTag(_f: com.google.protobuf.ByteString) = copy(`tag` = Some(_f))

  def clearBucket = copy(`bucket` = None)
  def clearKey = copy(`key` = None)
  def clearTag = copy(`tag` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`bucket`.isDefined) output.writeBytes(1, `bucket`.get)
    if (`key`.isDefined) output.writeBytes(2, `key`.get)
    if (`tag`.isDefined) output.writeBytes(3, `tag`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`bucket`.isDefined) __size += computeBytesSize(1, `bucket`.get)
    if (`key`.isDefined) __size += computeBytesSize(2, `key`.get)
    if (`tag`.isDefined) __size += computeBytesSize(3, `tag`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbLink = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: Option[com.google.protobuf.ByteString] = `bucket`
    var __key: Option[com.google.protobuf.ByteString] = `key`
    var __tag: Option[com.google.protobuf.ByteString] = `tag`

      def __newMerged = RpbLink(
        __bucket,
        __key,
        __tag)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = Some(in.readBytes())
      case 18      ⇒ __key = Some(in.readBytes())
      case 26      ⇒ __tag = Some(in.readBytes())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbLink) = {
    RpbLink(
      m.`bucket`.orElse(`bucket`),
      m.`key`.orElse(`key`),
      m.`tag`.orElse(`tag`))
  }

  def getDefaultInstanceForType = RpbLink.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbLink {
  @beans.BeanProperty val defaultInstance = new RpbLink()

  def parseFrom(data: Array[Byte]): RpbLink = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbLink = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbLink = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbLink = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbLink] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val TAG_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbLink) = defaultInstance.mergeFrom(prototype)

}
final case class RpbCounterUpdateReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `amount`: Long = 0L,
  `w`: Option[Int] = None,
  `dw`: Option[Int] = None,
  `pw`: Option[Int] = None,
  `returnvalue`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbCounterUpdateReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbCounterUpdateReq] {

  def setW(_f: Int) = copy(`w` = Some(_f))
  def setDw(_f: Int) = copy(`dw` = Some(_f))
  def setPw(_f: Int) = copy(`pw` = Some(_f))
  def setReturnvalue(_f: Boolean) = copy(`returnvalue` = Some(_f))

  def clearW = copy(`w` = None)
  def clearDw = copy(`dw` = None)
  def clearPw = copy(`pw` = None)
  def clearReturnvalue = copy(`returnvalue` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `key`)
    output.writeSInt64(3, `amount`)
    if (`w`.isDefined) output.writeUInt32(4, `w`.get)
    if (`dw`.isDefined) output.writeUInt32(5, `dw`.get)
    if (`pw`.isDefined) output.writeUInt32(6, `pw`.get)
    if (`returnvalue`.isDefined) output.writeBool(7, `returnvalue`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `key`)
    __size += computeSInt64Size(3, `amount`)
    if (`w`.isDefined) __size += computeUInt32Size(4, `w`.get)
    if (`dw`.isDefined) __size += computeUInt32Size(5, `dw`.get)
    if (`pw`.isDefined) __size += computeUInt32Size(6, `pw`.get)
    if (`returnvalue`.isDefined) __size += computeBoolSize(7, `returnvalue`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbCounterUpdateReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __amount: Long = 0L
    var __w: Option[Int] = `w`
    var __dw: Option[Int] = `dw`
    var __pw: Option[Int] = `pw`
    var __returnvalue: Option[Boolean] = `returnvalue`

      def __newMerged = RpbCounterUpdateReq(
        __bucket,
        __key,
        __amount,
        __w,
        __dw,
        __pw,
        __returnvalue)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = in.readBytes()
      case 24      ⇒ __amount = in.readSInt64()
      case 32      ⇒ __w = Some(in.readUInt32())
      case 40      ⇒ __dw = Some(in.readUInt32())
      case 48      ⇒ __pw = Some(in.readUInt32())
      case 56      ⇒ __returnvalue = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbCounterUpdateReq) = {
    RpbCounterUpdateReq(
      m.`bucket`,
      m.`key`,
      m.`amount`,
      m.`w`.orElse(`w`),
      m.`dw`.orElse(`dw`),
      m.`pw`.orElse(`pw`),
      m.`returnvalue`.orElse(`returnvalue`))
  }

  def getDefaultInstanceForType = RpbCounterUpdateReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbCounterUpdateReq {
  @beans.BeanProperty val defaultInstance = new RpbCounterUpdateReq()

  def parseFrom(data: Array[Byte]): RpbCounterUpdateReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbCounterUpdateReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbCounterUpdateReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbCounterUpdateReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbCounterUpdateReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val AMOUNT_FIELD_NUMBER = 3
  val W_FIELD_NUMBER = 4
  val DW_FIELD_NUMBER = 5
  val PW_FIELD_NUMBER = 6
  val RETURNVALUE_FIELD_NUMBER = 7

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbCounterUpdateReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbCounterUpdateResp(
  `value`: Option[Long] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbCounterUpdateResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbCounterUpdateResp] {

  def setValue(_f: Long) = copy(`value` = Some(_f))

  def clearValue = copy(`value` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`value`.isDefined) output.writeSInt64(1, `value`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`value`.isDefined) __size += computeSInt64Size(1, `value`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbCounterUpdateResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __value: Option[Long] = `value`

      def __newMerged = RpbCounterUpdateResp(
        __value)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 8       ⇒ __value = Some(in.readSInt64())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbCounterUpdateResp) = {
    RpbCounterUpdateResp(
      m.`value`.orElse(`value`))
  }

  def getDefaultInstanceForType = RpbCounterUpdateResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbCounterUpdateResp {
  @beans.BeanProperty val defaultInstance = new RpbCounterUpdateResp()

  def parseFrom(data: Array[Byte]): RpbCounterUpdateResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbCounterUpdateResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbCounterUpdateResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbCounterUpdateResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbCounterUpdateResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val VALUE_FIELD_NUMBER = 1

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbCounterUpdateResp) = defaultInstance.mergeFrom(prototype)

}
final case class RpbCounterGetReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `r`: Option[Int] = None,
  `pr`: Option[Int] = None,
  `basicQuorum`: Option[Boolean] = None,
  `notfoundOk`: Option[Boolean] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbCounterGetReq]
    with net.sandrogrzicic.scalabuff.Parser[RpbCounterGetReq] {

  def setR(_f: Int) = copy(`r` = Some(_f))
  def setPr(_f: Int) = copy(`pr` = Some(_f))
  def setBasicQuorum(_f: Boolean) = copy(`basicQuorum` = Some(_f))
  def setNotfoundOk(_f: Boolean) = copy(`notfoundOk` = Some(_f))

  def clearR = copy(`r` = None)
  def clearPr = copy(`pr` = None)
  def clearBasicQuorum = copy(`basicQuorum` = None)
  def clearNotfoundOk = copy(`notfoundOk` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `key`)
    if (`r`.isDefined) output.writeUInt32(3, `r`.get)
    if (`pr`.isDefined) output.writeUInt32(4, `pr`.get)
    if (`basicQuorum`.isDefined) output.writeBool(5, `basicQuorum`.get)
    if (`notfoundOk`.isDefined) output.writeBool(6, `notfoundOk`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `key`)
    if (`r`.isDefined) __size += computeUInt32Size(3, `r`.get)
    if (`pr`.isDefined) __size += computeUInt32Size(4, `pr`.get)
    if (`basicQuorum`.isDefined) __size += computeBoolSize(5, `basicQuorum`.get)
    if (`notfoundOk`.isDefined) __size += computeBoolSize(6, `notfoundOk`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbCounterGetReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __r: Option[Int] = `r`
    var __pr: Option[Int] = `pr`
    var __basicQuorum: Option[Boolean] = `basicQuorum`
    var __notfoundOk: Option[Boolean] = `notfoundOk`

      def __newMerged = RpbCounterGetReq(
        __bucket,
        __key,
        __r,
        __pr,
        __basicQuorum,
        __notfoundOk)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = in.readBytes()
      case 24      ⇒ __r = Some(in.readUInt32())
      case 32      ⇒ __pr = Some(in.readUInt32())
      case 40      ⇒ __basicQuorum = Some(in.readBool())
      case 48      ⇒ __notfoundOk = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbCounterGetReq) = {
    RpbCounterGetReq(
      m.`bucket`,
      m.`key`,
      m.`r`.orElse(`r`),
      m.`pr`.orElse(`pr`),
      m.`basicQuorum`.orElse(`basicQuorum`),
      m.`notfoundOk`.orElse(`notfoundOk`))
  }

  def getDefaultInstanceForType = RpbCounterGetReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbCounterGetReq {
  @beans.BeanProperty val defaultInstance = new RpbCounterGetReq()

  def parseFrom(data: Array[Byte]): RpbCounterGetReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbCounterGetReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbCounterGetReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbCounterGetReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbCounterGetReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val R_FIELD_NUMBER = 3
  val PR_FIELD_NUMBER = 4
  val BASIC_QUORUM_FIELD_NUMBER = 5
  val NOTFOUND_OK_FIELD_NUMBER = 6

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbCounterGetReq) = defaultInstance.mergeFrom(prototype)

}
final case class RpbCounterGetResp(
  `value`: Option[Long] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[RpbCounterGetResp]
    with net.sandrogrzicic.scalabuff.Parser[RpbCounterGetResp] {

  def setValue(_f: Long) = copy(`value` = Some(_f))

  def clearValue = copy(`value` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`value`.isDefined) output.writeSInt64(1, `value`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`value`.isDefined) __size += computeSInt64Size(1, `value`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): RpbCounterGetResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __value: Option[Long] = `value`

      def __newMerged = RpbCounterGetResp(
        __value)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 8       ⇒ __value = Some(in.readSInt64())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: RpbCounterGetResp) = {
    RpbCounterGetResp(
      m.`value`.orElse(`value`))
  }

  def getDefaultInstanceForType = RpbCounterGetResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object RpbCounterGetResp {
  @beans.BeanProperty val defaultInstance = new RpbCounterGetResp()

  def parseFrom(data: Array[Byte]): RpbCounterGetResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): RpbCounterGetResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): RpbCounterGetResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): RpbCounterGetResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[RpbCounterGetResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val VALUE_FIELD_NUMBER = 1

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: RpbCounterGetResp) = defaultInstance.mergeFrom(prototype)

}

object RiakKvPB {
  def registerAllExtensions(registry: com.google.protobuf.ExtensionRegistryLite) {
  }

}
