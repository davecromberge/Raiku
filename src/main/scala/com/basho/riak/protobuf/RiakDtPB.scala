// Generated by ScalaBuff, the Scala Protocol Buffers compiler. DO NOT EDIT!
// source: riak_dt.proto

package com.basho.riak.protobuf

final case class MapField(
  `name`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `type`: MapField.MapFieldType.EnumVal = MapField.MapFieldType._UNINITIALIZED) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[MapField]
    with net.sandrogrzicic.scalabuff.Parser[MapField] {

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `name`)
    output.writeEnum(2, `type`)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `name`)
    __size += computeEnumSize(2, `type`)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): MapField = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __name: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __type: MapField.MapFieldType.EnumVal = MapField.MapFieldType._UNINITIALIZED

      def __newMerged = MapField(
        __name,
        __type)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __name = in.readBytes()
      case 16      ⇒ __type = MapField.MapFieldType.valueOf(in.readEnum())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: MapField) = {
    MapField(
      m.`name`,
      m.`type`)
  }

  def getDefaultInstanceForType = MapField.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object MapField {
  @beans.BeanProperty val defaultInstance = new MapField()

  def parseFrom(data: Array[Byte]): MapField = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): MapField = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): MapField = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): MapField = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[MapField] = defaultInstance.mergeDelimitedFromStream(stream)

  val NAME_FIELD_NUMBER = 1
  val TYPE_FIELD_NUMBER = 2

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: MapField) = defaultInstance.mergeFrom(prototype)

  object MapFieldType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val COUNTER = new EnumVal { val name = "COUNTER"; val id = 1 }
    val SET = new EnumVal { val name = "SET"; val id = 2 }
    val REGISTER = new EnumVal { val name = "REGISTER"; val id = 3 }
    val FLAG = new EnumVal { val name = "FLAG"; val id = 4 }
    val MAP = new EnumVal { val name = "MAP"; val id = 5 }

    val COUNTER_VALUE = 1
    val SET_VALUE = 2
    val REGISTER_VALUE = 3
    val FLAG_VALUE = 4
    val MAP_VALUE = 5

    def valueOf(id: Int) = id match {
      case 1        ⇒ COUNTER
      case 2        ⇒ SET
      case 3        ⇒ REGISTER
      case 4        ⇒ FLAG
      case 5        ⇒ MAP
      case _default ⇒ throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class MapEntry(
  `field`: MapField = MapField.defaultInstance,
  `counterValue`: Option[Long] = None,
  `setValue`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `registerValue`: Option[com.google.protobuf.ByteString] = None,
  `flagValue`: Option[Boolean] = None,
  `mapValue`: scala.collection.immutable.Seq[MapEntry] = Vector.empty[MapEntry]) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[MapEntry]
    with net.sandrogrzicic.scalabuff.Parser[MapEntry] {

  def setCounterValue(_f: Long) = copy(`counterValue` = Some(_f))
  def setSetValue(_i: Int, _v: com.google.protobuf.ByteString) = copy(`setValue` = `setValue`.updated(_i, _v))
  def addSetValue(_f: com.google.protobuf.ByteString) = copy(`setValue` = `setValue` :+ _f)
  def addAllSetValue(_f: com.google.protobuf.ByteString*) = copy(`setValue` = `setValue` ++ _f)
  def addAllSetValue(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`setValue` = `setValue` ++ _f)
  def setRegisterValue(_f: com.google.protobuf.ByteString) = copy(`registerValue` = Some(_f))
  def setFlagValue(_f: Boolean) = copy(`flagValue` = Some(_f))
  def setMapValue(_i: Int, _v: MapEntry) = copy(`mapValue` = `mapValue`.updated(_i, _v))
  def addMapValue(_f: MapEntry) = copy(`mapValue` = `mapValue` :+ _f)
  def addAllMapValue(_f: MapEntry*) = copy(`mapValue` = `mapValue` ++ _f)
  def addAllMapValue(_f: TraversableOnce[MapEntry]) = copy(`mapValue` = `mapValue` ++ _f)

  def clearCounterValue = copy(`counterValue` = None)
  def clearSetValue = copy(`setValue` = Vector.empty[com.google.protobuf.ByteString])
  def clearRegisterValue = copy(`registerValue` = None)
  def clearFlagValue = copy(`flagValue` = None)
  def clearMapValue = copy(`mapValue` = Vector.empty[MapEntry])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeMessage(1, `field`)
    if (`counterValue`.isDefined) output.writeSInt64(2, `counterValue`.get)
    for (_v ← `setValue`) output.writeBytes(3, _v)
    if (`registerValue`.isDefined) output.writeBytes(4, `registerValue`.get)
    if (`flagValue`.isDefined) output.writeBool(5, `flagValue`.get)
    for (_v ← `mapValue`) output.writeMessage(6, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeMessageSize(1, `field`)
    if (`counterValue`.isDefined) __size += computeSInt64Size(2, `counterValue`.get)
    for (_v ← `setValue`) __size += computeBytesSize(3, _v)
    if (`registerValue`.isDefined) __size += computeBytesSize(4, `registerValue`.get)
    if (`flagValue`.isDefined) __size += computeBoolSize(5, `flagValue`.get)
    for (_v ← `mapValue`) __size += computeMessageSize(6, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): MapEntry = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __field: MapField = MapField.defaultInstance
    var __counterValue: Option[Long] = `counterValue`
    val __setValue: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `setValue`.toBuffer
    var __registerValue: Option[com.google.protobuf.ByteString] = `registerValue`
    var __flagValue: Option[Boolean] = `flagValue`
    val __mapValue: scala.collection.mutable.Buffer[MapEntry] = `mapValue`.toBuffer

      def __newMerged = MapEntry(
        __field,
        __counterValue,
        Vector(__setValue: _*),
        __registerValue,
        __flagValue,
        Vector(__mapValue: _*))
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __field = readMessage[MapField](in, __field, _emptyRegistry)
      case 16      ⇒ __counterValue = Some(in.readSInt64())
      case 26      ⇒ __setValue += in.readBytes()
      case 34      ⇒ __registerValue = Some(in.readBytes())
      case 40      ⇒ __flagValue = Some(in.readBool())
      case 50      ⇒ __mapValue += readMessage[MapEntry](in, MapEntry.defaultInstance, _emptyRegistry)
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: MapEntry) = {
    MapEntry(
      m.`field`,
      m.`counterValue`.orElse(`counterValue`),
      `setValue` ++ m.`setValue`,
      m.`registerValue`.orElse(`registerValue`),
      m.`flagValue`.orElse(`flagValue`),
      `mapValue` ++ m.`mapValue`)
  }

  def getDefaultInstanceForType = MapEntry.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object MapEntry {
  @beans.BeanProperty val defaultInstance = new MapEntry()

  def parseFrom(data: Array[Byte]): MapEntry = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): MapEntry = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): MapEntry = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): MapEntry = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[MapEntry] = defaultInstance.mergeDelimitedFromStream(stream)

  val FIELD_FIELD_NUMBER = 1
  val COUNTER_VALUE_FIELD_NUMBER = 2
  val SET_VALUE_FIELD_NUMBER = 3
  val REGISTER_VALUE_FIELD_NUMBER = 4
  val FLAG_VALUE_FIELD_NUMBER = 5
  val MAP_VALUE_FIELD_NUMBER = 6

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: MapEntry) = defaultInstance.mergeFrom(prototype)

}
final case class DtFetchReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `type`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `r`: Option[Int] = None,
  `pr`: Option[Int] = None,
  `basicQuorum`: Option[Boolean] = None,
  `notfoundOk`: Option[Boolean] = None,
  `timeout`: Option[Int] = None,
  `sloppyQuorum`: Option[Boolean] = None,
  `nVal`: Option[Int] = None,
  `includeContext`: Option[Boolean] = Some(true)) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[DtFetchReq]
    with net.sandrogrzicic.scalabuff.Parser[DtFetchReq] {

  def setR(_f: Int) = copy(`r` = Some(_f))
  def setPr(_f: Int) = copy(`pr` = Some(_f))
  def setBasicQuorum(_f: Boolean) = copy(`basicQuorum` = Some(_f))
  def setNotfoundOk(_f: Boolean) = copy(`notfoundOk` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setSloppyQuorum(_f: Boolean) = copy(`sloppyQuorum` = Some(_f))
  def setNVal(_f: Int) = copy(`nVal` = Some(_f))
  def setIncludeContext(_f: Boolean) = copy(`includeContext` = Some(_f))

  def clearR = copy(`r` = None)
  def clearPr = copy(`pr` = None)
  def clearBasicQuorum = copy(`basicQuorum` = None)
  def clearNotfoundOk = copy(`notfoundOk` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearSloppyQuorum = copy(`sloppyQuorum` = None)
  def clearNVal = copy(`nVal` = None)
  def clearIncludeContext = copy(`includeContext` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    output.writeBytes(2, `key`)
    output.writeBytes(3, `type`)
    if (`r`.isDefined) output.writeUInt32(4, `r`.get)
    if (`pr`.isDefined) output.writeUInt32(5, `pr`.get)
    if (`basicQuorum`.isDefined) output.writeBool(6, `basicQuorum`.get)
    if (`notfoundOk`.isDefined) output.writeBool(7, `notfoundOk`.get)
    if (`timeout`.isDefined) output.writeUInt32(8, `timeout`.get)
    if (`sloppyQuorum`.isDefined) output.writeBool(9, `sloppyQuorum`.get)
    if (`nVal`.isDefined) output.writeUInt32(10, `nVal`.get)
    if (`includeContext`.isDefined) output.writeBool(11, `includeContext`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    __size += computeBytesSize(2, `key`)
    __size += computeBytesSize(3, `type`)
    if (`r`.isDefined) __size += computeUInt32Size(4, `r`.get)
    if (`pr`.isDefined) __size += computeUInt32Size(5, `pr`.get)
    if (`basicQuorum`.isDefined) __size += computeBoolSize(6, `basicQuorum`.get)
    if (`notfoundOk`.isDefined) __size += computeBoolSize(7, `notfoundOk`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(8, `timeout`.get)
    if (`sloppyQuorum`.isDefined) __size += computeBoolSize(9, `sloppyQuorum`.get)
    if (`nVal`.isDefined) __size += computeUInt32Size(10, `nVal`.get)
    if (`includeContext`.isDefined) __size += computeBoolSize(11, `includeContext`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): DtFetchReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __type: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __r: Option[Int] = `r`
    var __pr: Option[Int] = `pr`
    var __basicQuorum: Option[Boolean] = `basicQuorum`
    var __notfoundOk: Option[Boolean] = `notfoundOk`
    var __timeout: Option[Int] = `timeout`
    var __sloppyQuorum: Option[Boolean] = `sloppyQuorum`
    var __nVal: Option[Int] = `nVal`
    var __includeContext: Option[Boolean] = `includeContext`

      def __newMerged = DtFetchReq(
        __bucket,
        __key,
        __type,
        __r,
        __pr,
        __basicQuorum,
        __notfoundOk,
        __timeout,
        __sloppyQuorum,
        __nVal,
        __includeContext)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = in.readBytes()
      case 26      ⇒ __type = in.readBytes()
      case 32      ⇒ __r = Some(in.readUInt32())
      case 40      ⇒ __pr = Some(in.readUInt32())
      case 48      ⇒ __basicQuorum = Some(in.readBool())
      case 56      ⇒ __notfoundOk = Some(in.readBool())
      case 64      ⇒ __timeout = Some(in.readUInt32())
      case 72      ⇒ __sloppyQuorum = Some(in.readBool())
      case 80      ⇒ __nVal = Some(in.readUInt32())
      case 88      ⇒ __includeContext = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: DtFetchReq) = {
    DtFetchReq(
      m.`bucket`,
      m.`key`,
      m.`type`,
      m.`r`.orElse(`r`),
      m.`pr`.orElse(`pr`),
      m.`basicQuorum`.orElse(`basicQuorum`),
      m.`notfoundOk`.orElse(`notfoundOk`),
      m.`timeout`.orElse(`timeout`),
      m.`sloppyQuorum`.orElse(`sloppyQuorum`),
      m.`nVal`.orElse(`nVal`),
      m.`includeContext`.orElse(`includeContext`))
  }

  def getDefaultInstanceForType = DtFetchReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object DtFetchReq {
  @beans.BeanProperty val defaultInstance = new DtFetchReq()

  def parseFrom(data: Array[Byte]): DtFetchReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): DtFetchReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): DtFetchReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): DtFetchReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[DtFetchReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val TYPE_FIELD_NUMBER = 3
  val R_FIELD_NUMBER = 4
  val PR_FIELD_NUMBER = 5
  val BASIC_QUORUM_FIELD_NUMBER = 6
  val NOTFOUND_OK_FIELD_NUMBER = 7
  val TIMEOUT_FIELD_NUMBER = 8
  val SLOPPY_QUORUM_FIELD_NUMBER = 9
  val N_VAL_FIELD_NUMBER = 10
  val INCLUDE_CONTEXT_FIELD_NUMBER = 11

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: DtFetchReq) = defaultInstance.mergeFrom(prototype)

}
final case class DtValue(
  `counterValue`: Option[Long] = None,
  `setValue`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `mapValue`: scala.collection.immutable.Seq[MapEntry] = Vector.empty[MapEntry]) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[DtValue]
    with net.sandrogrzicic.scalabuff.Parser[DtValue] {

  def setCounterValue(_f: Long) = copy(`counterValue` = Some(_f))
  def setSetValue(_i: Int, _v: com.google.protobuf.ByteString) = copy(`setValue` = `setValue`.updated(_i, _v))
  def addSetValue(_f: com.google.protobuf.ByteString) = copy(`setValue` = `setValue` :+ _f)
  def addAllSetValue(_f: com.google.protobuf.ByteString*) = copy(`setValue` = `setValue` ++ _f)
  def addAllSetValue(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`setValue` = `setValue` ++ _f)
  def setMapValue(_i: Int, _v: MapEntry) = copy(`mapValue` = `mapValue`.updated(_i, _v))
  def addMapValue(_f: MapEntry) = copy(`mapValue` = `mapValue` :+ _f)
  def addAllMapValue(_f: MapEntry*) = copy(`mapValue` = `mapValue` ++ _f)
  def addAllMapValue(_f: TraversableOnce[MapEntry]) = copy(`mapValue` = `mapValue` ++ _f)

  def clearCounterValue = copy(`counterValue` = None)
  def clearSetValue = copy(`setValue` = Vector.empty[com.google.protobuf.ByteString])
  def clearMapValue = copy(`mapValue` = Vector.empty[MapEntry])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`counterValue`.isDefined) output.writeSInt64(1, `counterValue`.get)
    for (_v ← `setValue`) output.writeBytes(2, _v)
    for (_v ← `mapValue`) output.writeMessage(3, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`counterValue`.isDefined) __size += computeSInt64Size(1, `counterValue`.get)
    for (_v ← `setValue`) __size += computeBytesSize(2, _v)
    for (_v ← `mapValue`) __size += computeMessageSize(3, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): DtValue = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __counterValue: Option[Long] = `counterValue`
    val __setValue: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `setValue`.toBuffer
    val __mapValue: scala.collection.mutable.Buffer[MapEntry] = `mapValue`.toBuffer

      def __newMerged = DtValue(
        __counterValue,
        Vector(__setValue: _*),
        Vector(__mapValue: _*))
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 8       ⇒ __counterValue = Some(in.readSInt64())
      case 18      ⇒ __setValue += in.readBytes()
      case 26      ⇒ __mapValue += readMessage[MapEntry](in, MapEntry.defaultInstance, _emptyRegistry)
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: DtValue) = {
    DtValue(
      m.`counterValue`.orElse(`counterValue`),
      `setValue` ++ m.`setValue`,
      `mapValue` ++ m.`mapValue`)
  }

  def getDefaultInstanceForType = DtValue.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object DtValue {
  @beans.BeanProperty val defaultInstance = new DtValue()

  def parseFrom(data: Array[Byte]): DtValue = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): DtValue = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): DtValue = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): DtValue = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[DtValue] = defaultInstance.mergeDelimitedFromStream(stream)

  val COUNTER_VALUE_FIELD_NUMBER = 1
  val SET_VALUE_FIELD_NUMBER = 2
  val MAP_VALUE_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: DtValue) = defaultInstance.mergeFrom(prototype)

}
final case class DtFetchResp(
  `context`: Option[com.google.protobuf.ByteString] = None,
  `type`: DtFetchResp.DataType.EnumVal = DtFetchResp.DataType._UNINITIALIZED,
  `value`: Option[DtValue] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[DtFetchResp]
    with net.sandrogrzicic.scalabuff.Parser[DtFetchResp] {

  def setContext(_f: com.google.protobuf.ByteString) = copy(`context` = Some(_f))
  def setValue(_f: DtValue) = copy(`value` = Some(_f))

  def clearContext = copy(`context` = None)
  def clearValue = copy(`value` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`context`.isDefined) output.writeBytes(1, `context`.get)
    output.writeEnum(2, `type`)
    if (`value`.isDefined) output.writeMessage(3, `value`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`context`.isDefined) __size += computeBytesSize(1, `context`.get)
    __size += computeEnumSize(2, `type`)
    if (`value`.isDefined) __size += computeMessageSize(3, `value`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): DtFetchResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __context: Option[com.google.protobuf.ByteString] = `context`
    var __type: DtFetchResp.DataType.EnumVal = DtFetchResp.DataType._UNINITIALIZED
    var __value: Option[DtValue] = `value`

      def __newMerged = DtFetchResp(
        __context,
        __type,
        __value)
    while (true) in.readTag match {
      case 0  ⇒ return __newMerged
      case 10 ⇒ __context = Some(in.readBytes())
      case 16 ⇒ __type = DtFetchResp.DataType.valueOf(in.readEnum())
      case 26 ⇒ __value = Some(readMessage[DtValue](in, __value.orElse({
        __value = DtValue.defaultInstance
        __value
      }).get, _emptyRegistry))
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: DtFetchResp) = {
    DtFetchResp(
      m.`context`.orElse(`context`),
      m.`type`,
      m.`value`.orElse(`value`))
  }

  def getDefaultInstanceForType = DtFetchResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object DtFetchResp {
  @beans.BeanProperty val defaultInstance = new DtFetchResp()

  def parseFrom(data: Array[Byte]): DtFetchResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): DtFetchResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): DtFetchResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): DtFetchResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[DtFetchResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val CONTEXT_FIELD_NUMBER = 1
  val TYPE_FIELD_NUMBER = 2
  val VALUE_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: DtFetchResp) = defaultInstance.mergeFrom(prototype)

  object DataType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val COUNTER = new EnumVal { val name = "COUNTER"; val id = 1 }
    val SET = new EnumVal { val name = "SET"; val id = 2 }
    val MAP = new EnumVal { val name = "MAP"; val id = 3 }

    val COUNTER_VALUE = 1
    val SET_VALUE = 2
    val MAP_VALUE = 3

    def valueOf(id: Int) = id match {
      case 1        ⇒ COUNTER
      case 2        ⇒ SET
      case 3        ⇒ MAP
      case _default ⇒ throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class CounterOp(
  `increment`: Option[Long] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[CounterOp]
    with net.sandrogrzicic.scalabuff.Parser[CounterOp] {

  def setIncrement(_f: Long) = copy(`increment` = Some(_f))

  def clearIncrement = copy(`increment` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`increment`.isDefined) output.writeSInt64(1, `increment`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`increment`.isDefined) __size += computeSInt64Size(1, `increment`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): CounterOp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __increment: Option[Long] = `increment`

      def __newMerged = CounterOp(
        __increment)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 8       ⇒ __increment = Some(in.readSInt64())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: CounterOp) = {
    CounterOp(
      m.`increment`.orElse(`increment`))
  }

  def getDefaultInstanceForType = CounterOp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object CounterOp {
  @beans.BeanProperty val defaultInstance = new CounterOp()

  def parseFrom(data: Array[Byte]): CounterOp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): CounterOp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): CounterOp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): CounterOp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[CounterOp] = defaultInstance.mergeDelimitedFromStream(stream)

  val INCREMENT_FIELD_NUMBER = 1

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: CounterOp) = defaultInstance.mergeFrom(prototype)

}
final case class SetOp(
  `adds`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `removes`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString]) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[SetOp]
    with net.sandrogrzicic.scalabuff.Parser[SetOp] {

  def setAdds(_i: Int, _v: com.google.protobuf.ByteString) = copy(`adds` = `adds`.updated(_i, _v))
  def addAdds(_f: com.google.protobuf.ByteString) = copy(`adds` = `adds` :+ _f)
  def addAllAdds(_f: com.google.protobuf.ByteString*) = copy(`adds` = `adds` ++ _f)
  def addAllAdds(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`adds` = `adds` ++ _f)
  def setRemoves(_i: Int, _v: com.google.protobuf.ByteString) = copy(`removes` = `removes`.updated(_i, _v))
  def addRemoves(_f: com.google.protobuf.ByteString) = copy(`removes` = `removes` :+ _f)
  def addAllRemoves(_f: com.google.protobuf.ByteString*) = copy(`removes` = `removes` ++ _f)
  def addAllRemoves(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`removes` = `removes` ++ _f)

  def clearAdds = copy(`adds` = Vector.empty[com.google.protobuf.ByteString])
  def clearRemoves = copy(`removes` = Vector.empty[com.google.protobuf.ByteString])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `adds`) output.writeBytes(1, _v)
    for (_v ← `removes`) output.writeBytes(2, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `adds`) __size += computeBytesSize(1, _v)
    for (_v ← `removes`) __size += computeBytesSize(2, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): SetOp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __adds: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `adds`.toBuffer
    val __removes: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `removes`.toBuffer

      def __newMerged = SetOp(
        Vector(__adds: _*),
        Vector(__removes: _*))
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __adds += in.readBytes()
      case 18      ⇒ __removes += in.readBytes()
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: SetOp) = {
    SetOp(
      `adds` ++ m.`adds`,
      `removes` ++ m.`removes`)
  }

  def getDefaultInstanceForType = SetOp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object SetOp {
  @beans.BeanProperty val defaultInstance = new SetOp()

  def parseFrom(data: Array[Byte]): SetOp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): SetOp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): SetOp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): SetOp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[SetOp] = defaultInstance.mergeDelimitedFromStream(stream)

  val ADDS_FIELD_NUMBER = 1
  val REMOVES_FIELD_NUMBER = 2

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: SetOp) = defaultInstance.mergeFrom(prototype)

}
final case class MapUpdate(
  `field`: MapField = MapField.defaultInstance,
  `counterOp`: Option[CounterOp] = None,
  `setOp`: Option[SetOp] = None,
  `registerOp`: Option[com.google.protobuf.ByteString] = None,
  `flagOp`: Option[MapUpdate.FlagOp.EnumVal] = None,
  `mapOp`: Option[MapOp] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[MapUpdate]
    with net.sandrogrzicic.scalabuff.Parser[MapUpdate] {

  def setCounterOp(_f: CounterOp) = copy(`counterOp` = Some(_f))
  def setSetOp(_f: SetOp) = copy(`setOp` = Some(_f))
  def setRegisterOp(_f: com.google.protobuf.ByteString) = copy(`registerOp` = Some(_f))
  def setFlagOp(_f: MapUpdate.FlagOp.EnumVal) = copy(`flagOp` = Some(_f))
  def setMapOp(_f: MapOp) = copy(`mapOp` = Some(_f))

  def clearCounterOp = copy(`counterOp` = None)
  def clearSetOp = copy(`setOp` = None)
  def clearRegisterOp = copy(`registerOp` = None)
  def clearFlagOp = copy(`flagOp` = None)
  def clearMapOp = copy(`mapOp` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeMessage(1, `field`)
    if (`counterOp`.isDefined) output.writeMessage(2, `counterOp`.get)
    if (`setOp`.isDefined) output.writeMessage(3, `setOp`.get)
    if (`registerOp`.isDefined) output.writeBytes(4, `registerOp`.get)
    if (`flagOp`.isDefined) output.writeEnum(5, `flagOp`.get)
    if (`mapOp`.isDefined) output.writeMessage(6, `mapOp`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeMessageSize(1, `field`)
    if (`counterOp`.isDefined) __size += computeMessageSize(2, `counterOp`.get)
    if (`setOp`.isDefined) __size += computeMessageSize(3, `setOp`.get)
    if (`registerOp`.isDefined) __size += computeBytesSize(4, `registerOp`.get)
    if (`flagOp`.isDefined) __size += computeEnumSize(5, `flagOp`.get)
    if (`mapOp`.isDefined) __size += computeMessageSize(6, `mapOp`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): MapUpdate = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __field: MapField = MapField.defaultInstance
    var __counterOp: Option[CounterOp] = `counterOp`
    var __setOp: Option[SetOp] = `setOp`
    var __registerOp: Option[com.google.protobuf.ByteString] = `registerOp`
    var __flagOp: Option[MapUpdate.FlagOp.EnumVal] = `flagOp`
    var __mapOp: Option[MapOp] = `mapOp`

      def __newMerged = MapUpdate(
        __field,
        __counterOp,
        __setOp,
        __registerOp,
        __flagOp,
        __mapOp)
    while (true) in.readTag match {
      case 0  ⇒ return __newMerged
      case 10 ⇒ __field = readMessage[MapField](in, __field, _emptyRegistry)
      case 18 ⇒ __counterOp = Some(readMessage[CounterOp](in, __counterOp.orElse({
        __counterOp = CounterOp.defaultInstance
        __counterOp
      }).get, _emptyRegistry))
      case 26 ⇒ __setOp = Some(readMessage[SetOp](in, __setOp.orElse({
        __setOp = SetOp.defaultInstance
        __setOp
      }).get, _emptyRegistry))
      case 34 ⇒ __registerOp = Some(in.readBytes())
      case 40 ⇒ __flagOp = Some(MapUpdate.FlagOp.valueOf(in.readEnum()))
      case 50 ⇒ __mapOp = Some(readMessage[MapOp](in, __mapOp.orElse({
        __mapOp = MapOp.defaultInstance
        __mapOp
      }).get, _emptyRegistry))
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: MapUpdate) = {
    MapUpdate(
      m.`field`,
      m.`counterOp`.orElse(`counterOp`),
      m.`setOp`.orElse(`setOp`),
      m.`registerOp`.orElse(`registerOp`),
      m.`flagOp`.orElse(`flagOp`),
      m.`mapOp`.orElse(`mapOp`))
  }

  def getDefaultInstanceForType = MapUpdate.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object MapUpdate {
  @beans.BeanProperty val defaultInstance = new MapUpdate()

  def parseFrom(data: Array[Byte]): MapUpdate = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): MapUpdate = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): MapUpdate = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): MapUpdate = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[MapUpdate] = defaultInstance.mergeDelimitedFromStream(stream)

  val FIELD_FIELD_NUMBER = 1
  val COUNTER_OP_FIELD_NUMBER = 2
  val SET_OP_FIELD_NUMBER = 3
  val REGISTER_OP_FIELD_NUMBER = 4
  val FLAG_OP_FIELD_NUMBER = 5
  val MAP_OP_FIELD_NUMBER = 6

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: MapUpdate) = defaultInstance.mergeFrom(prototype)

  object FlagOp extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val ENABLE = new EnumVal { val name = "ENABLE"; val id = 1 }
    val DISABLE = new EnumVal { val name = "DISABLE"; val id = 2 }

    val ENABLE_VALUE = 1
    val DISABLE_VALUE = 2

    def valueOf(id: Int) = id match {
      case 1        ⇒ ENABLE
      case 2        ⇒ DISABLE
      case _default ⇒ throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class MapOp(
  `adds`: scala.collection.immutable.Seq[MapField] = Vector.empty[MapField],
  `removes`: scala.collection.immutable.Seq[MapField] = Vector.empty[MapField],
  `updates`: scala.collection.immutable.Seq[MapUpdate] = Vector.empty[MapUpdate]) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[MapOp]
    with net.sandrogrzicic.scalabuff.Parser[MapOp] {

  def setAdds(_i: Int, _v: MapField) = copy(`adds` = `adds`.updated(_i, _v))
  def addAdds(_f: MapField) = copy(`adds` = `adds` :+ _f)
  def addAllAdds(_f: MapField*) = copy(`adds` = `adds` ++ _f)
  def addAllAdds(_f: TraversableOnce[MapField]) = copy(`adds` = `adds` ++ _f)
  def setRemoves(_i: Int, _v: MapField) = copy(`removes` = `removes`.updated(_i, _v))
  def addRemoves(_f: MapField) = copy(`removes` = `removes` :+ _f)
  def addAllRemoves(_f: MapField*) = copy(`removes` = `removes` ++ _f)
  def addAllRemoves(_f: TraversableOnce[MapField]) = copy(`removes` = `removes` ++ _f)
  def setUpdates(_i: Int, _v: MapUpdate) = copy(`updates` = `updates`.updated(_i, _v))
  def addUpdates(_f: MapUpdate) = copy(`updates` = `updates` :+ _f)
  def addAllUpdates(_f: MapUpdate*) = copy(`updates` = `updates` ++ _f)
  def addAllUpdates(_f: TraversableOnce[MapUpdate]) = copy(`updates` = `updates` ++ _f)

  def clearAdds = copy(`adds` = Vector.empty[MapField])
  def clearRemoves = copy(`removes` = Vector.empty[MapField])
  def clearUpdates = copy(`updates` = Vector.empty[MapUpdate])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v ← `adds`) output.writeMessage(1, _v)
    for (_v ← `removes`) output.writeMessage(2, _v)
    for (_v ← `updates`) output.writeMessage(3, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v ← `adds`) __size += computeMessageSize(1, _v)
    for (_v ← `removes`) __size += computeMessageSize(2, _v)
    for (_v ← `updates`) __size += computeMessageSize(3, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): MapOp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    val __adds: scala.collection.mutable.Buffer[MapField] = `adds`.toBuffer
    val __removes: scala.collection.mutable.Buffer[MapField] = `removes`.toBuffer
    val __updates: scala.collection.mutable.Buffer[MapUpdate] = `updates`.toBuffer

      def __newMerged = MapOp(
        Vector(__adds: _*),
        Vector(__removes: _*),
        Vector(__updates: _*))
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __adds += readMessage[MapField](in, MapField.defaultInstance, _emptyRegistry)
      case 18      ⇒ __removes += readMessage[MapField](in, MapField.defaultInstance, _emptyRegistry)
      case 26      ⇒ __updates += readMessage[MapUpdate](in, MapUpdate.defaultInstance, _emptyRegistry)
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: MapOp) = {
    MapOp(
      `adds` ++ m.`adds`,
      `removes` ++ m.`removes`,
      `updates` ++ m.`updates`)
  }

  def getDefaultInstanceForType = MapOp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object MapOp {
  @beans.BeanProperty val defaultInstance = new MapOp()

  def parseFrom(data: Array[Byte]): MapOp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): MapOp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): MapOp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): MapOp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[MapOp] = defaultInstance.mergeDelimitedFromStream(stream)

  val ADDS_FIELD_NUMBER = 1
  val REMOVES_FIELD_NUMBER = 2
  val UPDATES_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: MapOp) = defaultInstance.mergeFrom(prototype)

}
final case class DtOp(
  `counterOp`: Option[CounterOp] = None,
  `setOp`: Option[SetOp] = None,
  `mapOp`: Option[MapOp] = None) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[DtOp]
    with net.sandrogrzicic.scalabuff.Parser[DtOp] {

  def setCounterOp(_f: CounterOp) = copy(`counterOp` = Some(_f))
  def setSetOp(_f: SetOp) = copy(`setOp` = Some(_f))
  def setMapOp(_f: MapOp) = copy(`mapOp` = Some(_f))

  def clearCounterOp = copy(`counterOp` = None)
  def clearSetOp = copy(`setOp` = None)
  def clearMapOp = copy(`mapOp` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`counterOp`.isDefined) output.writeMessage(1, `counterOp`.get)
    if (`setOp`.isDefined) output.writeMessage(2, `setOp`.get)
    if (`mapOp`.isDefined) output.writeMessage(3, `mapOp`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`counterOp`.isDefined) __size += computeMessageSize(1, `counterOp`.get)
    if (`setOp`.isDefined) __size += computeMessageSize(2, `setOp`.get)
    if (`mapOp`.isDefined) __size += computeMessageSize(3, `mapOp`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): DtOp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __counterOp: Option[CounterOp] = `counterOp`
    var __setOp: Option[SetOp] = `setOp`
    var __mapOp: Option[MapOp] = `mapOp`

      def __newMerged = DtOp(
        __counterOp,
        __setOp,
        __mapOp)
    while (true) in.readTag match {
      case 0 ⇒ return __newMerged
      case 10 ⇒ __counterOp = Some(readMessage[CounterOp](in, __counterOp.orElse({
        __counterOp = CounterOp.defaultInstance
        __counterOp
      }).get, _emptyRegistry))
      case 18 ⇒ __setOp = Some(readMessage[SetOp](in, __setOp.orElse({
        __setOp = SetOp.defaultInstance
        __setOp
      }).get, _emptyRegistry))
      case 26 ⇒ __mapOp = Some(readMessage[MapOp](in, __mapOp.orElse({
        __mapOp = MapOp.defaultInstance
        __mapOp
      }).get, _emptyRegistry))
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: DtOp) = {
    DtOp(
      m.`counterOp`.orElse(`counterOp`),
      m.`setOp`.orElse(`setOp`),
      m.`mapOp`.orElse(`mapOp`))
  }

  def getDefaultInstanceForType = DtOp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object DtOp {
  @beans.BeanProperty val defaultInstance = new DtOp()

  def parseFrom(data: Array[Byte]): DtOp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): DtOp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): DtOp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): DtOp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[DtOp] = defaultInstance.mergeDelimitedFromStream(stream)

  val COUNTER_OP_FIELD_NUMBER = 1
  val SET_OP_FIELD_NUMBER = 2
  val MAP_OP_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: DtOp) = defaultInstance.mergeFrom(prototype)

}
final case class DtUpdateReq(
  `bucket`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `key`: Option[com.google.protobuf.ByteString] = None,
  `type`: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
  `context`: Option[com.google.protobuf.ByteString] = None,
  `op`: DtOp = DtOp.defaultInstance,
  `w`: Option[Int] = None,
  `dw`: Option[Int] = None,
  `pw`: Option[Int] = None,
  `returnBody`: Option[Boolean] = Some(false),
  `timeout`: Option[Int] = None,
  `sloppyQuorum`: Option[Boolean] = None,
  `nVal`: Option[Int] = None,
  `includeContext`: Option[Boolean] = Some(true)) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[DtUpdateReq]
    with net.sandrogrzicic.scalabuff.Parser[DtUpdateReq] {

  def setKey(_f: com.google.protobuf.ByteString) = copy(`key` = Some(_f))
  def setContext(_f: com.google.protobuf.ByteString) = copy(`context` = Some(_f))
  def setW(_f: Int) = copy(`w` = Some(_f))
  def setDw(_f: Int) = copy(`dw` = Some(_f))
  def setPw(_f: Int) = copy(`pw` = Some(_f))
  def setReturnBody(_f: Boolean) = copy(`returnBody` = Some(_f))
  def setTimeout(_f: Int) = copy(`timeout` = Some(_f))
  def setSloppyQuorum(_f: Boolean) = copy(`sloppyQuorum` = Some(_f))
  def setNVal(_f: Int) = copy(`nVal` = Some(_f))
  def setIncludeContext(_f: Boolean) = copy(`includeContext` = Some(_f))

  def clearKey = copy(`key` = None)
  def clearContext = copy(`context` = None)
  def clearW = copy(`w` = None)
  def clearDw = copy(`dw` = None)
  def clearPw = copy(`pw` = None)
  def clearReturnBody = copy(`returnBody` = None)
  def clearTimeout = copy(`timeout` = None)
  def clearSloppyQuorum = copy(`sloppyQuorum` = None)
  def clearNVal = copy(`nVal` = None)
  def clearIncludeContext = copy(`includeContext` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    output.writeBytes(1, `bucket`)
    if (`key`.isDefined) output.writeBytes(2, `key`.get)
    output.writeBytes(3, `type`)
    if (`context`.isDefined) output.writeBytes(4, `context`.get)
    output.writeMessage(5, `op`)
    if (`w`.isDefined) output.writeUInt32(6, `w`.get)
    if (`dw`.isDefined) output.writeUInt32(7, `dw`.get)
    if (`pw`.isDefined) output.writeUInt32(8, `pw`.get)
    if (`returnBody`.isDefined) output.writeBool(9, `returnBody`.get)
    if (`timeout`.isDefined) output.writeUInt32(10, `timeout`.get)
    if (`sloppyQuorum`.isDefined) output.writeBool(11, `sloppyQuorum`.get)
    if (`nVal`.isDefined) output.writeUInt32(12, `nVal`.get)
    if (`includeContext`.isDefined) output.writeBool(13, `includeContext`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    __size += computeBytesSize(1, `bucket`)
    if (`key`.isDefined) __size += computeBytesSize(2, `key`.get)
    __size += computeBytesSize(3, `type`)
    if (`context`.isDefined) __size += computeBytesSize(4, `context`.get)
    __size += computeMessageSize(5, `op`)
    if (`w`.isDefined) __size += computeUInt32Size(6, `w`.get)
    if (`dw`.isDefined) __size += computeUInt32Size(7, `dw`.get)
    if (`pw`.isDefined) __size += computeUInt32Size(8, `pw`.get)
    if (`returnBody`.isDefined) __size += computeBoolSize(9, `returnBody`.get)
    if (`timeout`.isDefined) __size += computeUInt32Size(10, `timeout`.get)
    if (`sloppyQuorum`.isDefined) __size += computeBoolSize(11, `sloppyQuorum`.get)
    if (`nVal`.isDefined) __size += computeUInt32Size(12, `nVal`.get)
    if (`includeContext`.isDefined) __size += computeBoolSize(13, `includeContext`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): DtUpdateReq = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __bucket: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __key: Option[com.google.protobuf.ByteString] = `key`
    var __type: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
    var __context: Option[com.google.protobuf.ByteString] = `context`
    var __op: DtOp = DtOp.defaultInstance
    var __w: Option[Int] = `w`
    var __dw: Option[Int] = `dw`
    var __pw: Option[Int] = `pw`
    var __returnBody: Option[Boolean] = `returnBody`
    var __timeout: Option[Int] = `timeout`
    var __sloppyQuorum: Option[Boolean] = `sloppyQuorum`
    var __nVal: Option[Int] = `nVal`
    var __includeContext: Option[Boolean] = `includeContext`

      def __newMerged = DtUpdateReq(
        __bucket,
        __key,
        __type,
        __context,
        __op,
        __w,
        __dw,
        __pw,
        __returnBody,
        __timeout,
        __sloppyQuorum,
        __nVal,
        __includeContext)
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __bucket = in.readBytes()
      case 18      ⇒ __key = Some(in.readBytes())
      case 26      ⇒ __type = in.readBytes()
      case 34      ⇒ __context = Some(in.readBytes())
      case 42      ⇒ __op = readMessage[DtOp](in, __op, _emptyRegistry)
      case 48      ⇒ __w = Some(in.readUInt32())
      case 56      ⇒ __dw = Some(in.readUInt32())
      case 64      ⇒ __pw = Some(in.readUInt32())
      case 72      ⇒ __returnBody = Some(in.readBool())
      case 80      ⇒ __timeout = Some(in.readUInt32())
      case 88      ⇒ __sloppyQuorum = Some(in.readBool())
      case 96      ⇒ __nVal = Some(in.readUInt32())
      case 104     ⇒ __includeContext = Some(in.readBool())
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: DtUpdateReq) = {
    DtUpdateReq(
      m.`bucket`,
      m.`key`.orElse(`key`),
      m.`type`,
      m.`context`.orElse(`context`),
      m.`op`,
      m.`w`.orElse(`w`),
      m.`dw`.orElse(`dw`),
      m.`pw`.orElse(`pw`),
      m.`returnBody`.orElse(`returnBody`),
      m.`timeout`.orElse(`timeout`),
      m.`sloppyQuorum`.orElse(`sloppyQuorum`),
      m.`nVal`.orElse(`nVal`),
      m.`includeContext`.orElse(`includeContext`))
  }

  def getDefaultInstanceForType = DtUpdateReq.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object DtUpdateReq {
  @beans.BeanProperty val defaultInstance = new DtUpdateReq()

  def parseFrom(data: Array[Byte]): DtUpdateReq = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): DtUpdateReq = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): DtUpdateReq = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): DtUpdateReq = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[DtUpdateReq] = defaultInstance.mergeDelimitedFromStream(stream)

  val BUCKET_FIELD_NUMBER = 1
  val KEY_FIELD_NUMBER = 2
  val TYPE_FIELD_NUMBER = 3
  val CONTEXT_FIELD_NUMBER = 4
  val OP_FIELD_NUMBER = 5
  val W_FIELD_NUMBER = 6
  val DW_FIELD_NUMBER = 7
  val PW_FIELD_NUMBER = 8
  val RETURN_BODY_FIELD_NUMBER = 9
  val TIMEOUT_FIELD_NUMBER = 10
  val SLOPPY_QUORUM_FIELD_NUMBER = 11
  val N_VAL_FIELD_NUMBER = 12
  val INCLUDE_CONTEXT_FIELD_NUMBER = 13

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: DtUpdateReq) = defaultInstance.mergeFrom(prototype)

}
final case class DtUpdateResp(
  `key`: Option[com.google.protobuf.ByteString] = None,
  `context`: Option[com.google.protobuf.ByteString] = None,
  `counterValue`: Option[Long] = None,
  `setValue`: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
  `mapValue`: scala.collection.immutable.Seq[MapEntry] = Vector.empty[MapEntry]) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[DtUpdateResp]
    with net.sandrogrzicic.scalabuff.Parser[DtUpdateResp] {

  def setKey(_f: com.google.protobuf.ByteString) = copy(`key` = Some(_f))
  def setContext(_f: com.google.protobuf.ByteString) = copy(`context` = Some(_f))
  def setCounterValue(_f: Long) = copy(`counterValue` = Some(_f))
  def setSetValue(_i: Int, _v: com.google.protobuf.ByteString) = copy(`setValue` = `setValue`.updated(_i, _v))
  def addSetValue(_f: com.google.protobuf.ByteString) = copy(`setValue` = `setValue` :+ _f)
  def addAllSetValue(_f: com.google.protobuf.ByteString*) = copy(`setValue` = `setValue` ++ _f)
  def addAllSetValue(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(`setValue` = `setValue` ++ _f)
  def setMapValue(_i: Int, _v: MapEntry) = copy(`mapValue` = `mapValue`.updated(_i, _v))
  def addMapValue(_f: MapEntry) = copy(`mapValue` = `mapValue` :+ _f)
  def addAllMapValue(_f: MapEntry*) = copy(`mapValue` = `mapValue` ++ _f)
  def addAllMapValue(_f: TraversableOnce[MapEntry]) = copy(`mapValue` = `mapValue` ++ _f)

  def clearKey = copy(`key` = None)
  def clearContext = copy(`context` = None)
  def clearCounterValue = copy(`counterValue` = None)
  def clearSetValue = copy(`setValue` = Vector.empty[com.google.protobuf.ByteString])
  def clearMapValue = copy(`mapValue` = Vector.empty[MapEntry])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`key`.isDefined) output.writeBytes(1, `key`.get)
    if (`context`.isDefined) output.writeBytes(2, `context`.get)
    if (`counterValue`.isDefined) output.writeSInt64(3, `counterValue`.get)
    for (_v ← `setValue`) output.writeBytes(4, _v)
    for (_v ← `mapValue`) output.writeMessage(5, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`key`.isDefined) __size += computeBytesSize(1, `key`.get)
    if (`context`.isDefined) __size += computeBytesSize(2, `context`.get)
    if (`counterValue`.isDefined) __size += computeSInt64Size(3, `counterValue`.get)
    for (_v ← `setValue`) __size += computeBytesSize(4, _v)
    for (_v ← `mapValue`) __size += computeMessageSize(5, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): DtUpdateResp = {
    import com.google.protobuf.ExtensionRegistryLite.{ getEmptyRegistry ⇒ _emptyRegistry }
    var __key: Option[com.google.protobuf.ByteString] = `key`
    var __context: Option[com.google.protobuf.ByteString] = `context`
    var __counterValue: Option[Long] = `counterValue`
    val __setValue: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = `setValue`.toBuffer
    val __mapValue: scala.collection.mutable.Buffer[MapEntry] = `mapValue`.toBuffer

      def __newMerged = DtUpdateResp(
        __key,
        __context,
        __counterValue,
        Vector(__setValue: _*),
        Vector(__mapValue: _*))
    while (true) in.readTag match {
      case 0       ⇒ return __newMerged
      case 10      ⇒ __key = Some(in.readBytes())
      case 18      ⇒ __context = Some(in.readBytes())
      case 24      ⇒ __counterValue = Some(in.readSInt64())
      case 34      ⇒ __setValue += in.readBytes()
      case 42      ⇒ __mapValue += readMessage[MapEntry](in, MapEntry.defaultInstance, _emptyRegistry)
      case default ⇒ if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: DtUpdateResp) = {
    DtUpdateResp(
      m.`key`.orElse(`key`),
      m.`context`.orElse(`context`),
      m.`counterValue`.orElse(`counterValue`),
      `setValue` ++ m.`setValue`,
      `mapValue` ++ m.`mapValue`)
  }

  def getDefaultInstanceForType = DtUpdateResp.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object DtUpdateResp {
  @beans.BeanProperty val defaultInstance = new DtUpdateResp()

  def parseFrom(data: Array[Byte]): DtUpdateResp = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): DtUpdateResp = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): DtUpdateResp = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): DtUpdateResp = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[DtUpdateResp] = defaultInstance.mergeDelimitedFromStream(stream)

  val KEY_FIELD_NUMBER = 1
  val CONTEXT_FIELD_NUMBER = 2
  val COUNTER_VALUE_FIELD_NUMBER = 3
  val SET_VALUE_FIELD_NUMBER = 4
  val MAP_VALUE_FIELD_NUMBER = 5

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: DtUpdateResp) = defaultInstance.mergeFrom(prototype)

}

object RiakDtPB {
  def registerAllExtensions(registry: com.google.protobuf.ExtensionRegistryLite) {
  }

}
